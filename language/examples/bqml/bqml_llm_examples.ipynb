{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RWwfxTOXHI56",
      "metadata": {
        "id": "RWwfxTOXHI56"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iZXx5I1XHPkv",
      "metadata": {
        "id": "iZXx5I1XHPkv"
      },
      "source": [
        "# BQML - LLM Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe-LcDp6HfRy",
      "metadata": {
        "id": "fe-LcDp6HfRy"
      },
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uvc6DhQ_WXN9",
      "metadata": {
        "id": "uvc6DhQ_WXN9"
      },
      "source": [
        "## Overview\n",
        "BigQuery ML (BQML) now integrates with Vertex LLMs (PaLM 2 for Text). In this tutorial, you are shown examples of how to use this feature to run NLP tasks against data stored in BigQuery.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_RiJpQX1BuX",
      "metadata": {
        "id": "n_RiJpQX1BuX"
      },
      "source": [
        "### Objectives\n",
        "The objective is to demonstrate some of the many ways LLMs can be applied to your BigQuery data using BigQuery ML.\n",
        "\n",
        "\n",
        "You will execute simple SQL statements that call the Vertex AI API with the (`ML.GENERATE_TEXT`) function to:\n",
        "\n",
        "- Summmarize and classify text\n",
        "- Perform entity recognition\n",
        "- Enrich data\n",
        "- Run Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hbGaRkPdW8h2",
      "metadata": {
        "id": "hbGaRkPdW8h2"
      },
      "source": [
        "### Services and Costs\n",
        "This tutorial uses the following Google Cloud data analytics and ML services, they are billable components of Google Cloud:\n",
        "\n",
        "* BigQuery & BigQuery ML <a href=\"https://cloud.google.com/bigquery/pricing\" target=\"_blank\">(pricing)</a>\n",
        "* Vertex AI API <a href=\"https://cloud.google.com/vertex-ai/pricing\" target=\"_blank\">(pricing)</a>\n",
        "\n",
        "Check out the [BQML Pricing page](https://cloud.google.com/bigquery/pricing#bqml) for a breakdown of costs are applied across these services.\n",
        "\n",
        "Use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uo6BplVWBKEG",
      "metadata": {
        "id": "uo6BplVWBKEG"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RkSpG3NGBHi6",
      "metadata": {
        "id": "RkSpG3NGBHi6"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-bigquery-connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmmLvtm-Wx0A",
      "metadata": {
        "id": "fmmLvtm-Wx0A"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable BigQuery Connection API](https://console.cloud.google.com/apis/library/bigqueryconnection.googleapis.com?_ga=2.83970457.1667545569.1683624898-1324157630.1682064685),\n",
        "[Enable Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com&_ga=2.121353995.2053869978.1687859460-1056062237.1685695596)\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rEJsq_xkCPm0",
      "metadata": {
        "id": "rEJsq_xkCPm0"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LsrH4xD6CQO5",
      "metadata": {
        "id": "LsrH4xD6CQO5"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vyX2PzO2Cttl",
      "metadata": {
        "id": "vyX2PzO2Cttl"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZuVcOtXaC0fU",
      "metadata": {
        "id": "ZuVcOtXaC0fU"
      },
      "outputs": [],
      "source": [
        "REGION = \"\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PYfiKTh1E1Sv",
      "metadata": {
        "id": "PYfiKTh1E1Sv"
      },
      "source": [
        "#### Setup Project Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_-q5vGIWdBiC",
      "metadata": {
        "id": "_-q5vGIWdBiC"
      },
      "outputs": [],
      "source": [
        "DATASET_ID = \"bqml_llm\"\n",
        "CONN_NAME = \"bqml_llm_conn\"\n",
        "CONN_SERVICE_ACCOUNT = \"\"\n",
        "LLM_MODEL_NAME = \"bqml-vertex-llm\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ga6HKImjhI8l",
      "metadata": {
        "id": "Ga6HKImjhI8l"
      },
      "source": [
        "### Authenticate to your Google Cloud account\n",
        "Run the cell below and follow the instructions when prompted to authenticate your account via OAuth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KiB5cLgc4g2j",
      "metadata": {
        "id": "KiB5cLgc4g2j"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EA2CDuZDXEs0",
      "metadata": {
        "id": "EA2CDuZDXEs0"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wRHOEQ-tYnet",
      "metadata": {
        "id": "wRHOEQ-tYnet"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_connection_v1 as bq_connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yo2m3VCXnXWV",
      "metadata": {
        "id": "yo2m3VCXnXWV"
      },
      "source": [
        "### Create BigQuery Cloud resource connection\n",
        "You will need to create a [Cloud resource connection](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection) to enable BigQuery to interact with Vertex AI services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1",
      "metadata": {
        "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1"
      },
      "outputs": [],
      "source": [
        "client = bq_connection.ConnectionServiceClient()\n",
        "new_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
        "exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
        "cloud_resource_properties = bq_connection.CloudResourceProperties({})\n",
        "\n",
        "try:\n",
        "    request = client.get_connection(\n",
        "        request=bq_connection.GetConnectionRequest(name=exists_conn_parent)\n",
        "    )\n",
        "    CONN_SERVICE_ACCOUNT = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n",
        "except Exception:\n",
        "    connection = bq_connection.types.Connection(\n",
        "        {\"friendly_name\": CONN_NAME, \"cloud_resource\": cloud_resource_properties}\n",
        "    )\n",
        "    request = bq_connection.CreateConnectionRequest(\n",
        "        {\n",
        "            \"parent\": new_conn_parent,\n",
        "            \"connection_id\": CONN_NAME,\n",
        "            \"connection\": connection,\n",
        "        }\n",
        "    )\n",
        "    response = client.create_connection(request)\n",
        "    CONN_SERVICE_ACCOUNT = (\n",
        "        f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n",
        "    )\n",
        "print(CONN_SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OqrFKwdUnqlW",
      "metadata": {
        "id": "OqrFKwdUnqlW"
      },
      "source": [
        "### Set permissions for Service Account\n",
        "The resource connection service account requires certain project-level permissions which are outlined in the <a href=\"https://cloud.google.com/bigquery/docs/bigquery-ml-remote-model-tutorial#set_up_access\" target=\"_blank\">Vertex AI function documentation</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pyOp6r_SeZ6I",
      "metadata": {
        "id": "pyOp6r_SeZ6I"
      },
      "outputs": [],
      "source": [
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/serviceusage.serviceUsageConsumer'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/bigquery.connectionUser'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/aiplatform.user'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aJ_rzE8-nsT",
      "metadata": {
        "id": "7aJ_rzE8-nsT"
      },
      "source": [
        "## Prepare BigQuery Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G6NYBJlSciEN",
      "metadata": {
        "id": "G6NYBJlSciEN"
      },
      "source": [
        "### Create a BigQuery Dataset\n",
        "You will need a BigQuery dataset to store your ML model and tables. Run the following to create a dataset within your project called `bqml_llm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYSwQkixctO9",
      "metadata": {
        "id": "NYSwQkixctO9"
      },
      "outputs": [],
      "source": [
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset = client.create_dataset(DATASET_ID, exists_ok=True)\n",
        "print(f\"Dataset {dataset.dataset_id} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J8lKov-Y-wkz",
      "metadata": {
        "id": "J8lKov-Y-wkz"
      },
      "source": [
        "Create a wrapper to use the BigQuery client to run queries and return the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y8F-vcik4JVK",
      "metadata": {
        "id": "Y8F-vcik4JVK"
      },
      "outputs": [],
      "source": [
        "# Wrapper to use BigQuery client to run query and return result\n",
        "\n",
        "\n",
        "def run_bq_query(sql: str):\n",
        "    \"\"\"\n",
        "    Input: SQL query, as a string, to execute in BigQuery\n",
        "    Returns the query results or error, if any\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query_job = client.query(sql)\n",
        "        result = query_job.result()\n",
        "        print(f\"JOB ID: {query_job.job_id} STATUS: {query_job.state}\")\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gJE6PHD_6vq9",
      "metadata": {
        "id": "gJE6PHD_6vq9"
      },
      "source": [
        "##Executing LLM using BigQuery ML"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xf-f6XKC618_",
      "metadata": {
        "id": "xf-f6XKC618_"
      },
      "source": [
        "To execute LLMs in BQML you will first need to create the LLM model and then execute the (`ML.GENERATE_TEXT`) function with a prompt. This can all be done in SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dTuIqYeEHF8Z",
      "metadata": {
        "id": "dTuIqYeEHF8Z"
      },
      "source": [
        "###Create Vertex AI Model\n",
        "\n",
        "You can create a Vertex AI remote model in BigQuery using the CREATE MODEL statement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9OUDRjzWsWg",
      "metadata": {
        "id": "f9OUDRjzWsWg"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "      CREATE OR REPLACE MODEL\n",
        "        `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`\n",
        "        REMOTE WITH CONNECTION\n",
        "          `{PROJECT_ID}.{REGION}.{CONN_NAME}`\n",
        "          OPTIONS ( remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "      \"\"\"\n",
        "result = run_bq_query(sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LyK-KKouqM7W",
      "metadata": {
        "id": "LyK-KKouqM7W"
      },
      "source": [
        "###Using the LLM model\n",
        "You can now use the (`ML.GENERATE_TEXT`) function to run advanced NLP tasks against free text or data stored in BigQuery.\n",
        "\n",
        "[The BQML documentation](https://cloud.google.com/bigquery/docs/generate-text#generate_text) gives further details on the parameters used: `temperature, max_output_tokens, top_p and top_k.`\n",
        "\n",
        "*Note: The table column with the input text must have the alias 'prompt'*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BWijPOQ3wOKD",
      "metadata": {
        "id": "BWijPOQ3wOKD"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Describe a cat in one paragraph\"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            *\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                '{PROMPT}' AS prompt\n",
        "              ),\n",
        "              STRUCT\n",
        "              (\n",
        "                1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output\n",
        "              ));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oBDGjTLQHeza",
      "metadata": {
        "id": "oBDGjTLQHeza"
      },
      "source": [
        "The table of results will include JSON that can be parsed to extract the content result.\n",
        "\n",
        "Setting the `flatten_json_output` paramter to TRUE will return a flattened JSON as a string: `ml_generate_text_llm_result`.\n",
        "\n",
        "For the rest of the examples, we will just display the prompt and `ml_generate_text_llm_result` for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ULKL_n9HHGfg",
      "metadata": {
        "id": "ULKL_n9HHGfg"
      },
      "outputs": [],
      "source": [
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l0dU6XNTUwQQ",
      "metadata": {
        "id": "l0dU6XNTUwQQ"
      },
      "source": [
        "##On to the fun stuff - Example Use Cases!\n",
        "\n",
        "The following examples explore using the BQML LLM model for content creation, text summarization, classification, entity recognition, data enrichment and sentiment analysis.\n",
        "\n",
        "When writing your own prompts, we recommend you first review these [Prompt Design best practices](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YmeeDBBrOJ3r",
      "metadata": {
        "id": "YmeeDBBrOJ3r"
      },
      "source": [
        "####Content Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y2LT134zQEGy",
      "metadata": {
        "id": "Y2LT134zQEGy"
      },
      "outputs": [],
      "source": [
        "# Use LLM to create marketing campaign copy based on recipient demographic and spending data\n",
        "sql = f\"\"\"\n",
        "          WITH\n",
        "            latest_sale AS (\n",
        "            SELECT u.id,u.first_name,u.email,u.postal_code,u.country,o.order_id,o.created_at,p.category,p.name\n",
        "            FROM\n",
        "              `bigquery-public-data.thelook_ecommerce.users` u\n",
        "            JOIN (\n",
        "              SELECT user_id,order_id,created_at,product_id,\n",
        "                ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn\n",
        "              FROM\n",
        "                `bigquery-public-data.thelook_ecommerce.order_items` ) o\n",
        "            ON u.id = o.user_id\n",
        "            JOIN `bigquery-public-data.thelook_ecommerce.products` p\n",
        "            ON o.product_id = p.id\n",
        "            WHERE o.rn = 1 AND p.category = \"Active\" and u.country = \"United States\"\n",
        "          )\n",
        "\n",
        "          SELECT\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('A user bought a product with this description: ', name,' Write a follow up marketing email mentioning the high-level product category of their purchase in one word, for example \"We hope you are enjoying your new t-shirt\", and encouraging the individual to shop with the store again using the coupon code RETURN10 for 10% off their next purchase. Provide two local outdoor activities they could pursue with their new purchase. They live in the zip code ', postal_code,'. Don not mention the brand of the product, just sign off the email with \"-TheLook.\" Address the email to: ', first_name) AS prompt\n",
        "              FROM\n",
        "                latest_sale\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SCreOP1si33Y",
      "metadata": {
        "id": "SCreOP1si33Y"
      },
      "source": [
        "####Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lNjtW8j3moUX",
      "metadata": {
        "id": "lNjtW8j3moUX"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please summarize this BBC news article into 25 words or less: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzg7El87fzWe",
      "metadata": {
        "id": "tzg7El87fzWe"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please rewrite this article to enable easier understanding for a person with a B1 level of English. Article: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM  `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT 5\n",
        "              ),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jf00IgH0jER_",
      "metadata": {
        "id": "jf00IgH0jER_"
      },
      "source": [
        "####Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m61p1jp8Fesm",
      "metadata": {
        "id": "m61p1jp8Fesm"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please categorize BBC news article into either tech, sport, business, politics, or entertainment and return the category. Here's an example. News article: Intel has unveiled research that could mean data is soon being moved around chips at the speed of light., Category: Tech ; News article: \", body, \", Category:\") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BfMmRrv4jMjp",
      "metadata": {
        "id": "BfMmRrv4jMjp"
      },
      "source": [
        "####Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k-8BuOYvERHh",
      "metadata": {
        "id": "k-8BuOYvERHh"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please return a bullet-point list of all sentences in this article that cite a statistic: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i_Go_5XMSei7",
      "metadata": {
        "id": "i_Go_5XMSei7"
      },
      "outputs": [],
      "source": [
        "# Entity Extraction on a product description using LLM\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please return the brand name listed in this product description. Here is an example. Product: TYR Sport Men's Solid Durafast Jammer Swim Suit, Brand: TYR ; Product: \", name,\" Brand: \") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.thelook_ecommerce.products`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6J_Hv1z7JqB",
      "metadata": {
        "id": "c6J_Hv1z7JqB"
      },
      "source": [
        "####Data Enrichment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ukt3rJomUQBB",
      "metadata": {
        "id": "ukt3rJomUQBB"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please provide the Koppen climate classification for a given US Zip Code. Here's an example. Zip Code: '36773', Koppen Classification: 'Cfa'; Zip Code: \", zipcode, \"Koppen Classification: \") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.census_bureau_usa.population_by_zip_2010`\n",
        "              LIMIT\n",
        "                5 ),\n",
        "              STRUCT(0.2 AS temperature,\n",
        "                50 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k, TRUE AS flatten_json_output))\n",
        "          \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5JzOqTnIizNw",
      "metadata": {
        "id": "5JzOqTnIizNw"
      },
      "source": [
        "####Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ALWl_i4oF-X",
      "metadata": {
        "id": "4ALWl_i4oF-X"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            review,\n",
        "            ml_generate_text_llm_result,\n",
        "\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please categorize this movie review as either 'Positive', 'Negative' or 'Neutral'. Here's an example. Review: 'I dislike this movie', Sentiment: Negative ; Review: \", review, \", Category:\") AS prompt,\n",
        "                review\n",
        "              FROM\n",
        "                `bigquery-public-data.imdb.reviews`\n",
        "              WHERE\n",
        "                UPPER(title) = 'TROY'\n",
        "              LIMIT\n",
        "                10 ),\n",
        "              STRUCT(0.2 AS temperature,\n",
        "                50 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k, TRUE AS flatten_json_output))\n",
        "          \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DBgDJ4lZW3UE",
      "metadata": {
        "id": "DBgDJ4lZW3UE"
      },
      "source": [
        "## Cleaning Up\n",
        "To clean up all Google Cloud resources used in this project, you can <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects\" target=\"_blank\">delete the Google Cloud\n",
        "project</a> you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Oa51GiesTqA",
      "metadata": {
        "id": "9Oa51GiesTqA"
      },
      "outputs": [],
      "source": [
        "# Delete BigQuery dataset, including the BigQuery ML models you just created, and the BigQuery Connection\n",
        "! bq rm -r -f $PROJECT_ID:$DATASET_ID\n",
        "! bq rm --connection --project_id=$PROJECT_ID --location=$REGION $CONN_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bqml_llm_examples.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
