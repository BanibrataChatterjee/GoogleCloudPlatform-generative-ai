{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RWwfxTOXHI56",
      "metadata": {
        "id": "RWwfxTOXHI56"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iZXx5I1XHPkv",
      "metadata": {
        "id": "iZXx5I1XHPkv"
      },
      "source": [
        "# BQML - LLM Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe-LcDp6HfRy",
      "metadata": {
        "id": "fe-LcDp6HfRy"
      },
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uvc6DhQ_WXN9",
      "metadata": {
        "id": "uvc6DhQ_WXN9"
      },
      "source": [
        "## Overview\n",
        "BigQuery ML (BQML) now integrates with Vertex LLMs (PaLM 2 for Text). With many organizations storing their data in BigQuery, you can now use Vertex AI LLMs to run NLP tasks directly in BigQuery, without needing to move your data\n",
        "\n",
        "In this tutorial, you are shown examples of how to use this feature to run NLP tasks against data stored in BigQuery.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_RiJpQX1BuX",
      "metadata": {
        "id": "n_RiJpQX1BuX"
      },
      "source": [
        "### Objectives\n",
        "The objective is to demonstrate some of the many ways LLMs can be applied to your BigQuery data using BigQuery ML.\n",
        "\n",
        "\n",
        "You will execute simple SQL statements that call the Vertex AI API with the (`ML.GENERATE_TEXT`) function to:\n",
        "\n",
        "- Summmarize and classify text\n",
        "- Perform entity recognition\n",
        "- Enrich data\n",
        "- Run sentiment analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hbGaRkPdW8h2",
      "metadata": {
        "id": "hbGaRkPdW8h2"
      },
      "source": [
        "### Services and Costs\n",
        "This tutorial uses the following Google Cloud data analytics and ML services, they are billable components of Google Cloud:\n",
        "\n",
        "* BigQuery & BigQuery ML <a href=\"https://cloud.google.com/bigquery/pricing\" target=\"_blank\">(pricing)</a>\n",
        "* Vertex AI API <a href=\"https://cloud.google.com/vertex-ai/pricing\" target=\"_blank\">(pricing)</a>\n",
        "\n",
        "Check out the [BQML Pricing page](https://cloud.google.com/bigquery/pricing#bqml) for a breakdown of costs are applied across these services.\n",
        "\n",
        "Use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uo6BplVWBKEG",
      "metadata": {
        "id": "uo6BplVWBKEG"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RkSpG3NGBHi6",
      "metadata": {
        "id": "RkSpG3NGBHi6"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-bigquery-connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OCYieookBsZ7",
      "metadata": {
        "id": "OCYieookBsZ7"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gTUc2uR3BsKi",
      "metadata": {
        "id": "gTUc2uR3BsKi"
      },
      "outputs": [],
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmmLvtm-Wx0A",
      "metadata": {
        "id": "fmmLvtm-Wx0A"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable BigQuery Connection API](https://console.cloud.google.com/apis/library/bigqueryconnection.googleapis.com?_ga=2.83970457.1667545569.1683624898-1324157630.1682064685),\n",
        "[Enable Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com&_ga=2.121353995.2053869978.1687859460-1056062237.1685695596)\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rEJsq_xkCPm0",
      "metadata": {
        "id": "rEJsq_xkCPm0"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LsrH4xD6CQO5",
      "metadata": {
        "id": "LsrH4xD6CQO5"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vyX2PzO2Cttl",
      "metadata": {
        "id": "vyX2PzO2Cttl"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZuVcOtXaC0fU",
      "metadata": {
        "id": "ZuVcOtXaC0fU"
      },
      "outputs": [],
      "source": [
        "REGION = \"\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PYfiKTh1E1Sv",
      "metadata": {
        "id": "PYfiKTh1E1Sv"
      },
      "source": [
        "#### Setup Project Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wcEmPOYZB8za",
      "metadata": {
        "id": "wcEmPOYZB8za"
      },
      "source": [
        "These variables will be used throughout this notebook\n",
        "\n",
        "\n",
        "*   **Dataset ID:** ID of BigQuery dataset\n",
        "*   **CONN_NAME**: Name of a BigQuery connector that will be used to connect to Vertex AI services\n",
        "*   **CONN_SERVICE_ACCOUNT**: Email address of the service account that you will use for your BigQuery connection. This will be generated later in the notebook.\n",
        "*   **LLM_MODEL_NAME**: Name given to the LLM model created in BigQuery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_-q5vGIWdBiC",
      "metadata": {
        "id": "_-q5vGIWdBiC"
      },
      "outputs": [],
      "source": [
        "DATASET_ID = \"bqml_llm\"\n",
        "CONN_NAME = \"bqml_llm_conn\"\n",
        "CONN_SERVICE_ACCOUNT = \"\"\n",
        "LLM_MODEL_NAME = \"bqml-vertex-llm\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ga6HKImjhI8l",
      "metadata": {
        "id": "Ga6HKImjhI8l"
      },
      "source": [
        "### Authenticate to your Google Cloud account\n",
        "\n",
        "If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env).\n",
        "\n",
        "If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KiB5cLgc4g2j",
      "metadata": {
        "id": "KiB5cLgc4g2j"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EA2CDuZDXEs0",
      "metadata": {
        "id": "EA2CDuZDXEs0"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wRHOEQ-tYnet",
      "metadata": {
        "id": "wRHOEQ-tYnet"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_connection_v1 as bq_connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yo2m3VCXnXWV",
      "metadata": {
        "id": "yo2m3VCXnXWV"
      },
      "source": [
        "### Create BigQuery Cloud resource connection\n",
        "\n",
        "You will need to create a [Cloud resource connection](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection) to enable BigQuery to interact with Vertex AI services:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1",
      "metadata": {
        "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1"
      },
      "outputs": [],
      "source": [
        "client = bq_connection.ConnectionServiceClient()\n",
        "new_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
        "exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
        "cloud_resource_properties = bq_connection.CloudResourceProperties({})\n",
        "\n",
        "try:\n",
        "    request = client.get_connection(\n",
        "        request=bq_connection.GetConnectionRequest(name=exists_conn_parent)\n",
        "    )\n",
        "    CONN_SERVICE_ACCOUNT = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n",
        "except Exception:\n",
        "    connection = bq_connection.types.Connection(\n",
        "        {\"friendly_name\": CONN_NAME, \"cloud_resource\": cloud_resource_properties}\n",
        "    )\n",
        "    request = bq_connection.CreateConnectionRequest(\n",
        "        {\n",
        "            \"parent\": new_conn_parent,\n",
        "            \"connection_id\": CONN_NAME,\n",
        "            \"connection\": connection,\n",
        "        }\n",
        "    )\n",
        "    response = client.create_connection(request)\n",
        "    CONN_SERVICE_ACCOUNT = (\n",
        "        f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n",
        "    )\n",
        "print(CONN_SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OqrFKwdUnqlW",
      "metadata": {
        "id": "OqrFKwdUnqlW"
      },
      "source": [
        "### Set permissions for Service Account\n",
        "The resource connection service account requires certain project-level permissions which are outlined in the <a href=\"https://cloud.google.com/bigquery/docs/bigquery-ml-remote-model-tutorial#set_up_access\" target=\"_blank\">Vertex AI function documentation</a>.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** If you are using Vertex AI workbench, the service account used by Vertex AI may not have sufficient permissions to add IAM policy bindings.\n",
        "\n",
        "The [IAM Grant Access](https://cloud.google.com/iam/docs/granting-changing-revoking-access#grant-single-role) page gives instructions on how these policy bindings can be added using Cloud Shell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pyOp6r_SeZ6I",
      "metadata": {
        "id": "pyOp6r_SeZ6I"
      },
      "outputs": [],
      "source": [
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/serviceusage.serviceUsageConsumer'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/bigquery.connectionUser'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/aiplatform.user'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aJ_rzE8-nsT",
      "metadata": {
        "id": "7aJ_rzE8-nsT"
      },
      "source": [
        "## Prepare BigQuery Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G6NYBJlSciEN",
      "metadata": {
        "id": "G6NYBJlSciEN"
      },
      "source": [
        "### Create a BigQuery Dataset\n",
        "You will need a BigQuery dataset to store your ML model and tables. Run the following to create a dataset within your project called `bqml_llm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYSwQkixctO9",
      "metadata": {
        "id": "NYSwQkixctO9"
      },
      "outputs": [],
      "source": [
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset = client.create_dataset(DATASET_ID, exists_ok=True)\n",
        "print(f\"Dataset {dataset.dataset_id} created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J8lKov-Y-wkz",
      "metadata": {
        "id": "J8lKov-Y-wkz"
      },
      "source": [
        "Create a wrapper to use the BigQuery client to run queries and return the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y8F-vcik4JVK",
      "metadata": {
        "id": "Y8F-vcik4JVK"
      },
      "outputs": [],
      "source": [
        "# Wrapper to use BigQuery client to run query and return result\n",
        "\n",
        "\n",
        "def run_bq_query(sql: str):\n",
        "    \"\"\"\n",
        "    Input: SQL query, as a string, to execute in BigQuery\n",
        "    Returns the query results or error, if any\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query_job = client.query(sql)\n",
        "        result = query_job.result()\n",
        "        print(f\"JOB ID: {query_job.job_id} STATUS: {query_job.state}\")\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gJE6PHD_6vq9",
      "metadata": {
        "id": "gJE6PHD_6vq9"
      },
      "source": [
        "## Executing LLM using BigQuery ML"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xf-f6XKC618_",
      "metadata": {
        "id": "xf-f6XKC618_"
      },
      "source": [
        "To execute LLMs in BQML you will first need to configure the LLM model and then execute the (`ML.GENERATE_TEXT`) function with a prompt. This can all be done in SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dTuIqYeEHF8Z",
      "metadata": {
        "id": "dTuIqYeEHF8Z"
      },
      "source": [
        "### Configure Vertex AI Model\n",
        "\n",
        "You can configure a Vertex AI remote model in BigQuery using the CREATE MODEL statement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9OUDRjzWsWg",
      "metadata": {
        "id": "f9OUDRjzWsWg"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "      CREATE OR REPLACE MODEL\n",
        "        `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`\n",
        "        REMOTE WITH CONNECTION\n",
        "          `{PROJECT_ID}.{REGION}.{CONN_NAME}`\n",
        "          OPTIONS ( remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "      \"\"\"\n",
        "result = run_bq_query(sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LyK-KKouqM7W",
      "metadata": {
        "id": "LyK-KKouqM7W"
      },
      "source": [
        "### Using the LLM model\n",
        "You can now use the (`ML.GENERATE_TEXT`) function to run advanced NLP tasks against free text or data stored in BigQuery.\n",
        "\n",
        "[The BQML documentation](https://cloud.google.com/bigquery/docs/generate-text#generate_text) gives further details on the parameters used: `temperature, max_output_tokens, top_p and top_k.`\n",
        "\n",
        "*Note: The table column with the input text must have the alias 'prompt'*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BWijPOQ3wOKD",
      "metadata": {
        "id": "BWijPOQ3wOKD"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Describe a cat in one paragraph\"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            *\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                '{PROMPT}' AS prompt\n",
        "              ),\n",
        "              STRUCT\n",
        "              (\n",
        "                1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output\n",
        "              ));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oBDGjTLQHeza",
      "metadata": {
        "id": "oBDGjTLQHeza"
      },
      "source": [
        "In this case, we provided a simple prompt to the LLM: describe a cat in one paragraph.\n",
        "\n",
        "The LLM response is returned as a table of results in BigQuery. The table includes JSON that can be parsed to extract the content result.\n",
        "\n",
        "Setting the `flatten_json_output` paramter to TRUE will return a flattened JSON as a string: `ml_generate_text_llm_result`.\n",
        "\n",
        "For the rest of the examples, we will just display the prompt and `ml_generate_text_llm_result` for simplicity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l0dU6XNTUwQQ",
      "metadata": {
        "id": "l0dU6XNTUwQQ"
      },
      "source": [
        "## Example Use Cases\n",
        "\n",
        "The following examples explore using the BQML LLM model for content creation, text summarization, classification, entity recognition, data enrichment and sentiment analysis.\n",
        "\n",
        "When writing your own prompts, we recommend you first review these [Prompt Design best practices](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YmeeDBBrOJ3r",
      "metadata": {
        "id": "YmeeDBBrOJ3r"
      },
      "source": [
        "#### Content Creation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ofIZ7ozZnSu",
      "metadata": {
        "id": "1ofIZ7ozZnSu"
      },
      "source": [
        "This examples creates a marketing campaign email based on recipient demographic and spending data. Commmerce data is taken from BigQuery's thelook_ecommerce public dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y2LT134zQEGy",
      "metadata": {
        "id": "Y2LT134zQEGy"
      },
      "outputs": [],
      "source": [
        "# Use LLM to create marketing campaign copy based on recipient demographic and spending data\n",
        "sql = f\"\"\"\n",
        "          WITH\n",
        "            latest_sale AS (\n",
        "            SELECT u.id,u.first_name,u.email,u.postal_code,u.country,o.order_id,o.created_at,p.category,p.name\n",
        "            FROM\n",
        "              `bigquery-public-data.thelook_ecommerce.users` u\n",
        "            JOIN (\n",
        "              SELECT user_id,order_id,created_at,product_id,\n",
        "                ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn\n",
        "              FROM\n",
        "                `bigquery-public-data.thelook_ecommerce.order_items` ) o\n",
        "            ON u.id = o.user_id\n",
        "            JOIN `bigquery-public-data.thelook_ecommerce.products` p\n",
        "            ON o.product_id = p.id\n",
        "            WHERE o.rn = 1 AND p.category = \"Active\" and u.country = \"United States\"\n",
        "          )\n",
        "\n",
        "          SELECT\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('A user bought a product with this description: ', name,' Write a follow up marketing email mentioning the high-level product category of their purchase in one word, for example \"We hope you are enjoying your new t-shirt\", and encouraging the individual to shop with the store again using the coupon code RETURN10 for 10% off their next purchase. Provide two local outdoor activities they could pursue with their new purchase. They live in the zip code ', postal_code,'. Don not mention the brand of the product, just sign off the email with \"-TheLook.\" Address the email to: ', first_name) AS prompt\n",
        "              FROM\n",
        "                latest_sale\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SCreOP1si33Y",
      "metadata": {
        "id": "SCreOP1si33Y"
      },
      "source": [
        "#### Text Summarization\n",
        "\n",
        "This example summarises lengthy news articles stored in the BigQuery BBC News public dataset into 25 words or less."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lNjtW8j3moUX",
      "metadata": {
        "id": "lNjtW8j3moUX"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please summarize this BBC news article into 25 words or less: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q_vDot-QZbst",
      "metadata": {
        "id": "Q_vDot-QZbst"
      },
      "source": [
        "This example rewrites news articles stored in the BigQuery BBC News public dataset into text that can be understood by a 10 year old."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzg7El87fzWe",
      "metadata": {
        "id": "tzg7El87fzWe"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please rewrite this article to enable easier understanding for a 12 year old. Article: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM  `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT 5\n",
        "              ),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jf00IgH0jER_",
      "metadata": {
        "id": "jf00IgH0jER_"
      },
      "source": [
        "#### Text Classification\n",
        "\n",
        "This example categorizes news articles into one of the following categories: tech, sport, business, politics, or entertainment. The articles are stored in the BigQuery BBC News public dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m61p1jp8Fesm",
      "metadata": {
        "id": "m61p1jp8Fesm"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please categorize BBC news article into either tech, sport, business, politics, or entertainment and return the category. Here's an example. News article: Intel has unveiled research that could mean data is soon being moved around chips at the speed of light., Category: Tech ; News article: \", body, \", Category:\") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BfMmRrv4jMjp",
      "metadata": {
        "id": "BfMmRrv4jMjp"
      },
      "source": [
        "#### Entity Recognition\n",
        "\n",
        "This example extracts the sentences from news articles that contain a statistic. The articles are stored in the BigQuery BBC News public dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k-8BuOYvERHh",
      "metadata": {
        "id": "k-8BuOYvERHh"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Please return a bullet-point list of all sentences in this article that cite a statistic: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rSP17UbCYDR_",
      "metadata": {
        "id": "rSP17UbCYDR_"
      },
      "source": [
        "This example extracts the brand names from product descriptions stored in the BigQuery thelook_ecommerce public dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i_Go_5XMSei7",
      "metadata": {
        "id": "i_Go_5XMSei7"
      },
      "outputs": [],
      "source": [
        "# Entity Extraction on a product description using LLM\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please return the brand name listed in this product description. Here is an example. Product: TYR Sport Men's Solid Durafast Jammer Swim Suit, Brand: TYR ; Product: \", name,\" Brand: \") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.thelook_ecommerce.products`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6J_Hv1z7JqB",
      "metadata": {
        "id": "c6J_Hv1z7JqB"
      },
      "source": [
        "#### Data Enrichment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ukt3rJomUQBB",
      "metadata": {
        "id": "ukt3rJomUQBB"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please provide the Koppen climate classification for a given US Zip Code. Here's an example. Zip Code: '36773', Koppen Classification: 'Cfa'; Zip Code: \", zipcode, \"Koppen Classification: \") AS prompt\n",
        "              FROM\n",
        "                `bigquery-public-data.census_bureau_usa.population_by_zip_2010`\n",
        "              LIMIT\n",
        "                5 ),\n",
        "              STRUCT(0.2 AS temperature,\n",
        "                50 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k, TRUE AS flatten_json_output))\n",
        "          \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5JzOqTnIizNw",
      "metadata": {
        "id": "5JzOqTnIizNw"
      },
      "source": [
        "#### Sentiment Analysis\n",
        "\n",
        "This example runs sentiment analysis on movie reviews stored in the BigQuery IMDB public dataset to determine whether the movie is positive, negative or neutral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ALWl_i4oF-X",
      "metadata": {
        "id": "4ALWl_i4oF-X"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            review,\n",
        "            ml_generate_text_llm_result,\n",
        "\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT(\"Please categorize this movie review as either 'Positive', 'Negative' or 'Neutral'. Here's an example. Review: 'I dislike this movie', Sentiment: Negative ; Review: \", review, \", Category:\") AS prompt,\n",
        "                review\n",
        "              FROM\n",
        "                `bigquery-public-data.imdb.reviews`\n",
        "              WHERE\n",
        "                UPPER(title) = 'TROY'\n",
        "              LIMIT\n",
        "                10 ),\n",
        "              STRUCT(0.2 AS temperature,\n",
        "                50 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k, TRUE AS flatten_json_output))\n",
        "          \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DBgDJ4lZW3UE",
      "metadata": {
        "id": "DBgDJ4lZW3UE"
      },
      "source": [
        "## Cleaning Up\n",
        "To clean up all Google Cloud resources used in this project, you can <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects\" target=\"_blank\">delete the Google Cloud\n",
        "project</a> you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial by uncommenting the below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Oa51GiesTqA",
      "metadata": {
        "id": "9Oa51GiesTqA"
      },
      "outputs": [],
      "source": [
        "# # Delete BigQuery dataset, including the BigQuery ML models you just created, and the BigQuery Connection\n",
        "# ! bq rm -r -f $PROJECT_ID:$DATASET_ID\n",
        "# ! bq rm --connection --project_id=$PROJECT_ID --location=$REGION $CONN_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prf0sOh3ER4A",
      "metadata": {
        "id": "prf0sOh3ER4A"
      },
      "source": [
        "## Wrap Up\n",
        "\n",
        "In this tutorial we have provided examples of how Vertex AI LLMs can be used to execute NLP tasks against data stored in BigQuery.\n",
        "\n",
        "Check out our [BigQuery ML LLM page](https://cloud.google.com/bigquery/docs/inference-overview#generative_ai) to learn more about remote models and generatave AI in BigQuery."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bqml_llm_examples.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
