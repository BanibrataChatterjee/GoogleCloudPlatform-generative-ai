{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "RWwfxTOXHI56"
      },
      "id": "RWwfxTOXHI56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to using BigQuery with Vertex AI LLMs"
      ],
      "metadata": {
        "id": "iZXx5I1XHPkv"
      },
      "id": "iZXx5I1XHPkv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/examples/bqml/llm_nlp_examples.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "fe-LcDp6HfRy"
      },
      "id": "fe-LcDp6HfRy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "[BigQuery ML](https://cloud.google.com/bigquery/docs/bqml-introduction) (BQML) now integrates with [Vertex AI LLMs](https://cloud.google.com/vertex-ai) (PaLM 2 for Text).\n",
        "\n",
        "Organizations can now use Vertex AI LLMs on text and structured data stored in BigQuery. This means that organizations can continue to use BigQuery for data analysis, while also taking advantage of the power of Vertex AI LLMs without the need to move their data.\n",
        "\n",
        "In this tutorial, you are shown examples of how to use this feature against data stored in BigQuery.\n"
      ],
      "metadata": {
        "id": "uvc6DhQ_WXN9"
      },
      "id": "uvc6DhQ_WXN9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives\n",
        "The objective is to demonstrate some of the many ways LLMs can be applied to your BigQuery data using BigQuery ML.\n",
        "\n",
        "\n",
        "You will execute simple SQL statements that call the Vertex AI API with the (`ML.GENERATE_TEXT`) function to:\n",
        "\n",
        "- Summmarize and classify text\n",
        "- Perform entity recognition\n",
        "- Enrich data\n",
        "- Run sentiment analysis\n"
      ],
      "metadata": {
        "id": "n_RiJpQX1BuX"
      },
      "id": "n_RiJpQX1BuX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Services and Costs\n",
        "This tutorial uses the following Google Cloud data analytics and ML services, they are billable components of Google Cloud:\n",
        "\n",
        "* BigQuery & BigQuery ML <a href=\"https://cloud.google.com/bigquery/pricing\" target=\"_blank\">(pricing)</a>\n",
        "* Vertex AI API <a href=\"https://cloud.google.com/vertex-ai/pricing\" target=\"_blank\">(pricing)</a>\n",
        "\n",
        "Check out the [BQML Pricing page](https://cloud.google.com/bigquery/pricing#bqml) for a breakdown of costs are applied across these services.\n",
        "\n",
        "Use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator)\n",
        "to generate a cost estimate based on your projected usage."
      ],
      "metadata": {
        "id": "hbGaRkPdW8h2"
      },
      "id": "hbGaRkPdW8h2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ],
      "metadata": {
        "id": "uo6BplVWBKEG"
      },
      "id": "uo6BplVWBKEG"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery-connection"
      ],
      "metadata": {
        "id": "RkSpG3NGBHi6"
      },
      "id": "RkSpG3NGBHi6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ],
      "metadata": {
        "id": "OCYieookBsZ7"
      },
      "id": "OCYieookBsZ7"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "gTUc2uR3BsKi"
      },
      "id": "gTUc2uR3BsKi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable BigQuery Connection API](https://console.cloud.google.com/apis/library/bigqueryconnection.googleapis.com?_ga=2.83970457.1667545569.1683624898-1324157630.1682064685),\n",
        "[Enable Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com&_ga=2.121353995.2053869978.1687859460-1056062237.1685695596)\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ],
      "metadata": {
        "id": "fmmLvtm-Wx0A"
      },
      "id": "fmmLvtm-Wx0A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ],
      "metadata": {
        "id": "rEJsq_xkCPm0"
      },
      "id": "rEJsq_xkCPm0"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ],
      "metadata": {
        "id": "LsrH4xD6CQO5"
      },
      "id": "LsrH4xD6CQO5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  BigQuery Region\n",
        "\n",
        "You can also change the `REGION` variable when creating the BigQuery dataset and Cloud resource connection.\n",
        "\n",
        "For now, only the `us` multi-region and `us-central1` single region are supported for remote model services in BigQuery.\n",
        "\n",
        "**We recommend setting the region to `US` to provide access to all public datasets used below.**\n",
        "\n",
        "Learn more about [BigQuery public dataset regions](https://cloud.google.com/bigquery/public-data?gad=1&gclid=CjwKCAjw_aemBhBLEiwAT98FMhtM2q0Il2M4xU_eLwO_mAJpaZuuzBlQCNEkHKDDI-snZyGguxqnaRoCBdYQAvD_BwE&gclsrc=aw.ds#public_dataset_locations)."
      ],
      "metadata": {
        "id": "vyX2PzO2Cttl"
      },
      "id": "vyX2PzO2Cttl"
    },
    {
      "cell_type": "code",
      "source": [
        "REGION = \"\"  # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "ZuVcOtXaC0fU"
      },
      "id": "ZuVcOtXaC0fU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup Project Variables"
      ],
      "metadata": {
        "id": "PYfiKTh1E1Sv"
      },
      "id": "PYfiKTh1E1Sv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "These variables will be used throughout this notebook\n",
        "\n",
        "\n",
        "*   **DATASET_ID:** ID of BigQuery dataset\n",
        "*   **CONN_NAME**: Name of a BigQuery connector that will be used to connect to Vertex AI services\n",
        "*   **CONN_SERVICE_ACCOUNT**: Email address of the service account that you will use for your BigQuery connection. This will be generated later in the notebook.\n",
        "*   **LLM_MODEL_NAME**: Name given to the LLM created in BigQuery\n",
        "\n"
      ],
      "metadata": {
        "id": "wcEmPOYZB8za"
      },
      "id": "wcEmPOYZB8za"
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ID = \"bqml_llm\"\n",
        "CONN_NAME = 'bqml_llm_conn'\n",
        "CONN_SERVICE_ACCOUNT = ''\n",
        "LLM_MODEL_NAME = 'bqml-vertex-llm'"
      ],
      "metadata": {
        "id": "_-q5vGIWdBiC"
      },
      "id": "_-q5vGIWdBiC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate to your Google Cloud account\n",
        "\n",
        "If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env).\n",
        "\n",
        "If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n"
      ],
      "metadata": {
        "id": "Ga6HKImjhI8l"
      },
      "id": "Ga6HKImjhI8l"
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ],
      "metadata": {
        "id": "KiB5cLgc4g2j"
      },
      "id": "KiB5cLgc4g2j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EA2CDuZDXEs0"
      },
      "id": "EA2CDuZDXEs0"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery, bigquery_connection_v1 as bq_connection"
      ],
      "metadata": {
        "id": "wRHOEQ-tYnet"
      },
      "id": "wRHOEQ-tYnet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create BigQuery Cloud resource connection\n",
        "\n",
        "You will need to create a [Cloud resource connection](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection) to enable BigQuery to interact with Vertex AI services:"
      ],
      "metadata": {
        "id": "yo2m3VCXnXWV"
      },
      "id": "yo2m3VCXnXWV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1",
      "metadata": {
        "id": "379c93f2-2ce3-4963-b355-d18ffc77dbb1"
      },
      "outputs": [],
      "source": [
        "client = bq_connection.ConnectionServiceClient()\n",
        "new_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
        "exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
        "cloud_resource_properties = bq_connection.CloudResourceProperties({})\n",
        "\n",
        "# Try to use an existing connection if one already exists. If not, create a new one.\n",
        "try:\n",
        "  request = client.get_connection(request=bq_connection.GetConnectionRequest(name=exists_conn_parent))\n",
        "  CONN_SERVICE_ACCOUNT = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n",
        "except Exception:\n",
        "  connection = bq_connection.types.Connection(\n",
        "          {\n",
        "              \"friendly_name\": CONN_NAME,\n",
        "              \"cloud_resource\": cloud_resource_properties\n",
        "          }\n",
        "      )\n",
        "  request = bq_connection.CreateConnectionRequest(\n",
        "          {\n",
        "              \"parent\": new_conn_parent,\n",
        "              \"connection_id\": CONN_NAME,\n",
        "              \"connection\": connection\n",
        "          }\n",
        "      )\n",
        "  response = client.create_connection(request)\n",
        "  CONN_SERVICE_ACCOUNT = f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n",
        "print(CONN_SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set permissions for Service Account\n",
        "The resource connection service account requires certain project-level permissions which are outlined in the <a href=\"https://cloud.google.com/bigquery/docs/bigquery-ml-remote-model-tutorial#set_up_access\" target=\"_blank\">Vertex AI function documentation</a>.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** If you are using Vertex AI Workbench, the service account used by Vertex AI may not have sufficient permissions to add IAM policy bindings.\n",
        "\n",
        "The [IAM Grant Access](https://cloud.google.com/iam/docs/granting-changing-revoking-access#grant-single-role) page gives instructions on how these policy bindings can be added using Cloud Shell."
      ],
      "metadata": {
        "id": "OqrFKwdUnqlW"
      },
      "id": "OqrFKwdUnqlW"
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/serviceusage.serviceUsageConsumer'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/bigquery.connectionUser'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/aiplatform.user'"
      ],
      "metadata": {
        "id": "pyOp6r_SeZ6I"
      },
      "id": "pyOp6r_SeZ6I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare BigQuery Dataset"
      ],
      "metadata": {
        "id": "7aJ_rzE8-nsT"
      },
      "id": "7aJ_rzE8-nsT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a BigQuery Dataset\n",
        "You will need a BigQuery dataset to store your ML model and tables. This dataset must be created in the same region used by the BigQuery Cloud resource connection.\n",
        "\n",
        "Run the following to create a dataset within your project called `bqml_llm`:"
      ],
      "metadata": {
        "id": "G6NYBJlSciEN"
      },
      "id": "G6NYBJlSciEN"
    },
    {
      "cell_type": "code",
      "source": [
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "dataset_id = f\"\"\"{PROJECT_ID}.{DATASET_ID}\"\"\"\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "dataset.location = REGION\n",
        "\n",
        "dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "print(f\"Dataset {dataset.dataset_id} created.\")"
      ],
      "metadata": {
        "id": "NYSwQkixctO9"
      },
      "id": "NYSwQkixctO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a wrapper to use the BigQuery client to run queries and return the result:"
      ],
      "metadata": {
        "id": "J8lKov-Y-wkz"
      },
      "id": "J8lKov-Y-wkz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper to use BigQuery client to run query and return result\n",
        "def run_bq_query(sql: str):\n",
        "  \"\"\"\n",
        "  Input: SQL query, as a string, to execute in BigQuery\n",
        "  Returns the query results or error, if any\n",
        "  \"\"\"\n",
        "  try:\n",
        "    query_job = client.query(sql)\n",
        "    result = query_job.result()\n",
        "    print(f\"JOB ID: {query_job.job_id} STATUS: {query_job.state}\")\n",
        "    return result\n",
        "\n",
        "  except Exception as e:\n",
        "    raise Exception(str(e))\n"
      ],
      "metadata": {
        "id": "Y8F-vcik4JVK"
      },
      "id": "Y8F-vcik4JVK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using LLMs with BigQuery ML"
      ],
      "metadata": {
        "id": "gJE6PHD_6vq9"
      },
      "id": "gJE6PHD_6vq9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use LLMs with BigQuery ML you will first need to configure the LLM and then execute the (`ML.GENERATE_TEXT`) function with a prompt. This can all be done in SQL."
      ],
      "metadata": {
        "id": "xf-f6XKC618_"
      },
      "id": "xf-f6XKC618_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Vertex AI Model\n",
        "\n",
        "You can configure a Vertex AI remote model in BigQuery using the CREATE MODEL statement:"
      ],
      "metadata": {
        "id": "dTuIqYeEHF8Z"
      },
      "id": "dTuIqYeEHF8Z"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "      CREATE OR REPLACE MODEL\n",
        "        `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`\n",
        "        REMOTE WITH CONNECTION\n",
        "          `{PROJECT_ID}.{REGION}.{CONN_NAME}`\n",
        "          OPTIONS ( remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "      \"\"\"\n",
        "result = run_bq_query(sql)"
      ],
      "metadata": {
        "id": "f9OUDRjzWsWg"
      },
      "id": "f9OUDRjzWsWg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the LLM\n",
        "You can use the LLMs in BQML by executing the (`ML.GENERATE_TEXT`) function against free text or data stored in BigQuery.\n",
        "\n",
        "[The BQML documentation](https://cloud.google.com/bigquery/docs/generate-text#generate_text) gives further details on the parameters used: `temperature, max_output_tokens, top_p and top_k.`\n",
        "\n",
        "*Note: The table column with the input text must have the alias 'prompt'*\n",
        "\n"
      ],
      "metadata": {
        "id": "LyK-KKouqM7W"
      },
      "id": "LyK-KKouqM7W"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Describe a cat in one paragraph'\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            *\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                '{PROMPT}' AS prompt\n",
        "              ),\n",
        "              STRUCT\n",
        "              (\n",
        "                1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output\n",
        "              ));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "BWijPOQ3wOKD"
      },
      "id": "BWijPOQ3wOKD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the LLM responded to the simple prompt to describe a cat in one paragraph.\n",
        "\n",
        "The LLM response is returned as a table of results in BigQuery. The table includes JSON that can be parsed to extract the content result.\n",
        "\n",
        "Setting the `flatten_json_output` paramter to TRUE will return a flattened JSON as a string: `ml_generate_text_llm_result`.\n",
        "\n",
        "For the rest of the examples, you can just display the prompt and `ml_generate_text_llm_result` for simplicity."
      ],
      "metadata": {
        "id": "oBDGjTLQHeza"
      },
      "id": "oBDGjTLQHeza"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Use Cases\n",
        "\n",
        "The following examples explore using the BQML LLM for content creation, text summarization, classification, entity recognition, data enrichment and sentiment analysis.\n",
        "\n",
        "When writing your own prompts, we recommend you first review these [Prompt Design best practices](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_prompt_design.ipynb)."
      ],
      "metadata": {
        "id": "l0dU6XNTUwQQ"
      },
      "id": "l0dU6XNTUwQQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Classification\n",
        "\n",
        "This example categorizes news articles into one of the following categories: tech, sport, business, politics, or entertainment. The articles are stored in the BigQuery BBC News public dataset."
      ],
      "metadata": {
        "id": "jf00IgH0jER_"
      },
      "id": "jf00IgH0jER_"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Please categorize this BBC news article into either tech, sport, business, politics, or entertainment and return the category. Here is an example. News article: Intel has unveiled research that could mean data is soon being moved around chips at the speed of light., Category: Tech '\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            body AS article_body,\n",
        "            CONCAT('{PROMPT}','News article: ', 'article_body', ', Category:') as prompt_template,\n",
        "            ml_generate_text_llm_result as llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}','News article: ', body, ', Category:') AS prompt,\n",
        "                body\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "m61p1jp8Fesm"
      },
      "id": "m61p1jp8Fesm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Summarization\n",
        "\n",
        "This example rewrites news articles stored in the BigQuery BBC News public dataset into text that can be understood by a 12 year old."
      ],
      "metadata": {
        "id": "SCreOP1si33Y"
      },
      "id": "SCreOP1si33Y"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Please rewrite this article to enable easier understanding for a 12 year old. Article: '\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            body as article_before,\n",
        "            CONCAT('{PROMPT}', 'article_before') as prompt_template,\n",
        "            ml_generate_text_llm_result as llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt,\n",
        "                body\n",
        "              FROM  `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT 5\n",
        "              ),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "tzg7El87fzWe"
      },
      "id": "tzg7El87fzWe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example summarises lengthy news articles stored in the BigQuery BBC News public dataset into 25 words or less"
      ],
      "metadata": {
        "id": "y3awToblHGzH"
      },
      "id": "y3awToblHGzH"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Please summarize this BBC news article into 25 words or less: '\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            body as article_before,\n",
        "            ARRAY_LENGTH(SPLIT(body, ' ')) AS word_count_before,\n",
        "            CONCAT('{PROMPT}') as prompt_template,\n",
        "            ml_generate_text_llm_result as article_after,\n",
        "            ARRAY_LENGTH(SPLIT(ml_generate_text_llm_result, ' ')) AS word_count_after,\n",
        "            1-ARRAY_LENGTH(SPLIT(ml_generate_text_llm_result, ' '))/ARRAY_LENGTH(SPLIT(body, ' ')) as percent_reduction_words\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt,\n",
        "                body\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "lNjtW8j3moUX"
      },
      "id": "lNjtW8j3moUX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word count of the results may not always be within the the 25 words requested and so further [prompt engineering](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_prompt_design.ipynb) may be required."
      ],
      "metadata": {
        "id": "jVDeKe3YHk1J"
      },
      "id": "jVDeKe3YHk1J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entity Recognition\n",
        "\n",
        "This example extracts the sentences from news articles that contain a statistic. The articles are stored in the BigQuery BBC News public dataset."
      ],
      "metadata": {
        "id": "BfMmRrv4jMjp"
      },
      "id": "BfMmRrv4jMjp"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Please return a bullet-point list of all sentences in this article that cite a statistic: '\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            body AS article_body,\n",
        "            CONCAT('{PROMPT}', 'article_body') AS prompt,\n",
        "            ml_generate_text_llm_result AS llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', body) AS prompt,\n",
        "                body\n",
        "              FROM\n",
        "                `bigquery-public-data.bbc_news.fulltext`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "k-8BuOYvERHh"
      },
      "id": "k-8BuOYvERHh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example extracts the brand names from product descriptions stored in the BigQuery thelook_ecommerce public dataset."
      ],
      "metadata": {
        "id": "rSP17UbCYDR_"
      },
      "id": "rSP17UbCYDR_"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"Please return the brand name listed in this product description. Here is an example. Product: TYR Sport Mens Solid Durafast Jammer Swim Suit, Brand: TYR ; Product: \"\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            name AS product_description,\n",
        "            CONCAT('{PROMPT}', 'product_description,',' Brand: ') as prompt_template,\n",
        "            ml_generate_text_llm_result as llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}', name,' Brand: ') AS prompt,\n",
        "                name\n",
        "              FROM\n",
        "                `bigquery-public-data.thelook_ecommerce.products`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature, 1024 AS max_output_tokens, 0.8 AS top_p, 40 AS top_k, TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "i_Go_5XMSei7"
      },
      "id": "i_Go_5XMSei7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment Analysis\n",
        "\n",
        "This example runs sentiment analysis on movie reviews stored in the BigQuery IMDB public dataset to determine whether the movie is positive, negative or neutral."
      ],
      "metadata": {
        "id": "5JzOqTnIizNw"
      },
      "id": "5JzOqTnIizNw"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'Please categorize this movie review as either Positive, Negative or Neutral. Here is an example. Review: I dislike this movie, Sentiment: Negative'\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            review,\n",
        "            CONCAT('{PROMPT}',' Review: review Category:') as prompt_template,\n",
        "            ml_generate_text_llm_result as llm_result\n",
        "\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT}',' Review: ', review, ', Category:') AS prompt,\n",
        "                review\n",
        "              FROM\n",
        "                `bigquery-public-data.imdb.reviews`\n",
        "              WHERE\n",
        "                UPPER(title) = 'TROY'\n",
        "              LIMIT\n",
        "                10 ),\n",
        "              STRUCT(0.2 AS temperature,\n",
        "                50 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k, TRUE AS flatten_json_output))\n",
        "          \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "4ALWl_i4oF-X"
      },
      "id": "4ALWl_i4oF-X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Content Creation\n",
        "\n"
      ],
      "metadata": {
        "id": "YmeeDBBrOJ3r"
      },
      "id": "YmeeDBBrOJ3r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This examples creates a marketing campaign email based on recipient demographic and spending data. Commmerce data is taken from BigQuery's [thelook eCommerce public dataset](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce)."
      ],
      "metadata": {
        "id": "1ofIZ7ozZnSu"
      },
      "id": "1ofIZ7ozZnSu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you will need to join the order_items, products, and users tables of the dataset in order to get a table that includes the information for the email, including the item purchased, description of that item, and demographic data about the purchaser."
      ],
      "metadata": {
        "id": "iS6MFUvZ09cN"
      },
      "id": "iS6MFUvZ09cN"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "      CREATE OR REPLACE TABLE\n",
        "        `{PROJECT_ID}.{DATASET_ID}.purchases` AS\n",
        "      SELECT\n",
        "        u.id,\n",
        "        u.first_name,\n",
        "        u.email,\n",
        "        u.postal_code,\n",
        "        u.country,\n",
        "        o.order_id,\n",
        "        o.created_at,\n",
        "        p.category,\n",
        "        p.name\n",
        "      FROM\n",
        "        `bigquery-public-data.thelook_ecommerce.users` u\n",
        "      JOIN (\n",
        "        SELECT\n",
        "          user_id,\n",
        "          order_id,\n",
        "          created_at,\n",
        "          product_id,\n",
        "          ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn\n",
        "        FROM\n",
        "          `bigquery-public-data.thelook_ecommerce.order_items`\n",
        "      ) o\n",
        "      ON\n",
        "        u.id = o.user_id\n",
        "      JOIN\n",
        "        `bigquery-public-data.thelook_ecommerce.products` p\n",
        "      ON\n",
        "        o.product_id = p.id\n",
        "      WHERE\n",
        "        o.rn = 1 AND p.category = \"Active\" AND u.country = \"United States\";\n",
        "       \"\"\"\n",
        "\n",
        "result = run_bq_query(sql)"
      ],
      "metadata": {
        "id": "eMjm_YCrsKmC"
      },
      "id": "eMjm_YCrsKmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querying the new table, you will see a comprehensive set of data for each purchase."
      ],
      "metadata": {
        "id": "ypwarbiXtWaM"
      },
      "id": "ypwarbiXtWaM"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM\n",
        "            `{PROJECT_ID}.{DATASET_ID}.purchases`\n",
        "        LIMIT\n",
        "            10;\n",
        "      \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe().head(10)"
      ],
      "metadata": {
        "id": "B49ngc6dsYkR"
      },
      "id": "B49ngc6dsYkR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you will prepare the prompt for the LLM, incorporating the item's name and the purchaser's name and postal code.\n",
        "\n"
      ],
      "metadata": {
        "id": "N8CX3Hwntd2D"
      },
      "id": "N8CX3Hwntd2D"
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_PART1 = 'A user bought a product with this description: '\n",
        "PROMPT_PART2 = ' Write a follow up marketing email mentioning the high-level product category of their purchase in one word, for example \"We hope you are enjoying your new t-shirt\". '\n",
        "PROMPT_PART3 = 'Encourage the individual to shop with the store again using the coupon code RETURN10 for 10% off their next purchase. '\n",
        "PROMPT_PART4 = 'Provide two local outdoor activities they could pursue with their new purchase. They live in the zip code '\n",
        "PROMPT_PART5 = '. Do not mention the brand of the product, just sign off the email with \"-TheLook.\" Address the email to: '\n",
        "\n",
        "sql = f\"\"\"\n",
        "          SELECT\n",
        "            prompt,\n",
        "            ml_generate_text_llm_result\n",
        "          FROM\n",
        "            ML.GENERATE_TEXT(\n",
        "              MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_NAME}`,\n",
        "              (\n",
        "              SELECT\n",
        "                CONCAT('{PROMPT_PART1}',name,'{PROMPT_PART2}','{PROMPT_PART3}','{PROMPT_PART4}',postal_code,'{PROMPT_PART5}',first_name) AS prompt\n",
        "              FROM\n",
        "                `{PROJECT_ID}.{DATASET_ID}.purchases`\n",
        "              LIMIT\n",
        "                5),\n",
        "              STRUCT(1 AS temperature,\n",
        "                1024 AS max_output_tokens,\n",
        "                0.8 AS top_p,\n",
        "                40 AS top_k,\n",
        "                TRUE AS flatten_json_output));\n",
        "        \"\"\"\n",
        "result = run_bq_query(sql)\n",
        "result.to_dataframe()"
      ],
      "metadata": {
        "id": "Y2LT134zQEGy"
      },
      "id": "Y2LT134zQEGy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Up\n",
        "To clean up all Google Cloud resources used in this project, you can <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects\" target=\"_blank\">delete the Google Cloud\n",
        "project</a> you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial by uncommenting the below:"
      ],
      "metadata": {
        "id": "DBgDJ4lZW3UE"
      },
      "id": "DBgDJ4lZW3UE"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Delete BigQuery dataset, including the BigQuery ML models you just created, and the BigQuery Connection\n",
        "# ! bq rm -r -f $PROJECT_ID:$DATASET_ID\n",
        "# ! bq rm --connection --project_id=$PROJECT_ID --location=$REGION $CONN_NAME"
      ],
      "metadata": {
        "id": "9Oa51GiesTqA"
      },
      "id": "9Oa51GiesTqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrap Up\n",
        "\n",
        "In this tutorial we have shown how to integrate BQML with Vertex AI LLMs, and given examples of how the new `ML.GENERATE_TEXT` function can be applied directly to data stored in BigQuery.\n",
        "\n",
        "Check out our [BigQuery ML LLM page](https://cloud.google.com/bigquery/docs/inference-overview#generative_ai) to learn more about remote models and generative AI in BigQuery."
      ],
      "metadata": {
        "id": "prf0sOh3ER4A"
      },
      "id": "prf0sOh3ER4A"
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m102",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}