{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d19cb-2a93-41c7-ae4f-0acb34d0d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74701bc3-3b29-491c-9aa3-3058139ebc47",
   "metadata": {},
   "source": [
    "# **Generate training dataset for NMT(Neural Machine Translation) model training using DOCX files**\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.sandbox.google.com/drive/1Nl-cMDCjpOtIGsc830WFDtcNEmp5iPt-#scrollTo=KJnDAscARbav&uniqifier=1\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/vision/use-cases/generative-ai/language/translation/translation_training_data_generator.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/translation\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37171934-2b07-4632-9829-e7afc403f03d",
   "metadata": {
    "tags": []
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author | [Abhijat Gupta](https://github.com/abhijat-gupta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163cc8e-8360-45e1-91a1-eb61f3d9e014",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "\n",
    "[Cloud Translation API](https://cloud.google.com/translate/docs) uses Google's neural machine translation technology to let you dynamically translate text through the API using a Google pre-trained, custom model, or a translation specialized large language model (LLMs). \n",
    "\n",
    "It comes in [Basic and Advanced](https://cloud.google.com/translate/docs/editions) editions. Both provide fast and dynamic translation, but Advanced offers customization features, such as domain-specific translation, formatted document translation, and batch translation.\n",
    "\n",
    "The first 500,000 characters sent to the API to process (Basic and Advanced combined) per month are free (not applicable to LLMs).\n",
    "\n",
    "## Objective\n",
    "\n",
    "### Key Features\n",
    "1. Paragraphs are converted into line-pairs of less than 200 words.\n",
    "2. Tables in documents are converted into a line-pair with each row as a separate line-pair.\n",
    "3. Limit of 200 words per line is handled.\n",
    "4. Empty or blank lines are not added to the TSV.\n",
    "\n",
    "This notebook enables you to generate a TSV file out of documents(docx) for training NMT(neural machine translation) model. The generated TSV file will contain the source and target line pairs for 2 languages in 2 columns respectively. Limit of 200 words for a line is handled within the code. Example: If a line is exceeding 200 words, it won't be added to the training dataset, but will be captured and returned in a dictionary so that you can decide on how to convert it to line-pair of less than 200 words.\n",
    "The code also removes any blank or empty lines in a document from both source and reference before making line-pairs. This makes sure that both the documents do not mismatch with line-pairs due to empty lines.\n",
    "\n",
    "\n",
    "## How to use the notebook\n",
    "\n",
    "##### input: a dictionary containing source and reference GCS paths.\n",
    "\n",
    "##### output: a single TSV file, 2 dictionaries\n",
    "\n",
    "##### Steps to follow:\n",
    "- Provide as many source and reference files in the input dictionary: `source_ref_dictionary`, *key* being the source file path and reference file path as its *value*\n",
    "- Trigger all the cells after providing the input.\n",
    "- The TSV gets created in your local path.\n",
    "\n",
    "\n",
    "\n",
    "## Costs\n",
    "\n",
    "Learn about [Translation pricing](https://cloud.google.com/translate/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093fb72-bc78-49c0-95e3-01ac8b539da7",
   "metadata": {},
   "source": [
    "## **Getting Started**\n",
    "### Install docx and pyPDF2 SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abf771-97ee-4d53-8a90-eb147ecfa0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --proxy \"\" pyPDF2 --quiet\n",
    "# !pip install --proxy \"\" docx --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b63a2-b137-4850-9f92-dfd6a3001b70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4eff707-719c-4476-be4c-bb115037132a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2413d-2c02-4331-90e8-e37d6cb1086d",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-notebooks?hl=en).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de65a7-1d6c-4821-8d07-bd744808d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827b568-379a-4d3c-86ce-a3335a50034b",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de446f1-f275-49fb-85c1-e8e6bcf7822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import docx\n",
    "import PyPDF2\n",
    "\n",
    "from docx.table import _Cell, Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.document import Document as _Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b4218-64e3-41a3-9bdb-07a3e4e4f0b7",
   "metadata": {},
   "source": [
    "### output TSV file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb117d58-5cd0-47f9-9b45-5b7a87e37dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_file_name = \"your_tsv_file_name.tsv\"  # file name for the output tabular TSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fed12-35e5-44f3-a5e1-42a7651008cb",
   "metadata": {},
   "source": [
    "### source and reference paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d5e525-1ddc-4784-a747-718da49b259d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_ref_dictionary = {\n",
    "    \"source_path1.docx\": \"reference_path1.docx\",\n",
    "    \"source_path2.docx\": \"reference_path2.docx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a426e-1522-4867-8da0-04ffc377f5f5",
   "metadata": {},
   "source": [
    "### Generate TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141174ab-aab1-4a07-9411-df16cd6b7bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_document_objects(src_path, ref_path, source_bucket_name: str):\n",
    "    \"\"\"Fetches a source document and its translated/reference version from GCS bucket.\"\"\"\n",
    "\n",
    "    client = storage.Client()\n",
    "\n",
    "    ref_file_name = ref_path.split(source_bucket_name + \"/\")[1]\n",
    "    file_name = src_path.split(source_bucket_name + \"/\")[1]\n",
    "\n",
    "    try:\n",
    "        bucket = client.get_bucket(source_bucket_name)\n",
    "        src_blob = bucket.get_blob(file_name)\n",
    "        ref_blob = bucket.get_blob(ref_file_name)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "    src_file_downloaded_name = file_name.split(\"source/\")[1]\n",
    "    ref_file_downloaded_name = ref_file_name.split(\"reference/\")[1]\n",
    "\n",
    "    src_filepath = os.path.join(os.getcwd(), src_file_downloaded_name + \"_local.docx\")\n",
    "    ref_filepath = os.path.join(os.getcwd(), ref_file_downloaded_name + \"_local.docx\")\n",
    "\n",
    "    with open(src_filepath, \"wb\") as src_f:\n",
    "        src_blob.download_to_file(src_f)\n",
    "    src_f.close()\n",
    "\n",
    "    with open(ref_filepath, \"wb\") as ref_f:\n",
    "        ref_blob.download_to_file(ref_f)\n",
    "    ref_f.close()\n",
    "    if \".pdf\" in file_name:\n",
    "        source = PyPDF2.PdfReader(src_filepath)\n",
    "        reference = PyPDF2.PdfReader(ref_filepath)\n",
    "\n",
    "    else:\n",
    "        source = docx.Document(src_filepath)\n",
    "        reference = docx.Document(ref_filepath)\n",
    "\n",
    "    return source, reference\n",
    "\n",
    "\n",
    "def iter_block_items(parent):\n",
    "    \"\"\"\n",
    "    Generate a reference to each paragraph and table child within *parent*,\n",
    "    in document order. Each returned value is an instance of either Table or\n",
    "    Paragraph. *parent* would most commonly be a reference to a main\n",
    "    Document object, but also works for a _Cell object, which itself can\n",
    "    contain paragraphs and tables.\n",
    "    \"\"\"\n",
    "    if isinstance(parent, _Document):\n",
    "        parent_elm = parent.element.body\n",
    "    elif isinstance(parent, _Cell):\n",
    "        parent_elm = parent._tc\n",
    "    elif isinstance(parent, _Row):\n",
    "        parent_elm = parent._tr\n",
    "    else:\n",
    "        raise ValueError(\"something's not right\")\n",
    "    for child in parent_elm.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            yield Paragraph(child, parent)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            yield Table(child, parent)\n",
    "\n",
    "\n",
    "def make_tsv(source_ref_dictionary, tsv_file_name: str):\n",
    "    \"\"\"\n",
    "    - This function reads the source and reference/translated documents from local paths iteratively, block-by-block.\n",
    "    - A page blocks can be: Paragraphs and Tables.\n",
    "    - In order to generate correct pairs, the type of blocks should be same for both source and reference.\n",
    "    - If a block don't match, it get captured in mismatched_block dictionary and will not be added to the TSV. The Iteration stops and a TSV is created uptill the matching blocks.\n",
    "    - ONLY docx format is supported.\n",
    "    - Creates and saves the TSV in local path(Can be configured to save in GCS bucket).\n",
    "    - Returns the mismatched blocks from the documents as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    for src_path, ref_path in source_ref_dictionary.items():\n",
    "        if src_path is None or src_path == \"\":\n",
    "            return \"source file path is invalid.\"\n",
    "        if ref_path is None or ref_path == \"\":\n",
    "            return \"translated/reference file path is invalid.\"\n",
    "        if src_path.split(\".\", -1)[::-1][0] != ref_path.split(\".\", -1)[::-1][0]:\n",
    "            return \"source and translated versions are in different format.\"\n",
    "\n",
    "    tsv_file = os.path.join(os.getcwd(), tsv_file_name)\n",
    "    if \".pdf\" in src_path.split(src_path.split(\"gs://\")[1].split(\"/\")[0] + \"/\")[1]:\n",
    "        return \"PDFs are not supported. Process exited.\"\n",
    "\n",
    "    try:\n",
    "        mismatched_block = {}\n",
    "        more_than_200_words = {}\n",
    "        for source_path, reference_path in source_ref_dictionary.items():\n",
    "            source_bucket_name = source_path.split(\"gs://\")[1].split(\"/\")[0]\n",
    "            source, reference = get_document_objects(\n",
    "                source_path, reference_path, source_bucket_name\n",
    "            )\n",
    "\n",
    "            with open(tsv_file, \"a\") as tsv_f:\n",
    "                for para in source.paragraphs:\n",
    "                    if len(para.text.strip()) == 0:\n",
    "                        p = para._element\n",
    "                        p.getparent().remove(p)\n",
    "                        p._p = p._element = None\n",
    "                for para in reference.paragraphs:\n",
    "                    if len(para.text.strip()) == 0:\n",
    "                        p = para._element\n",
    "                        p.getparent().remove(p)\n",
    "                        p._p = p._element = None\n",
    "\n",
    "                for src_block, ref_block in zip(\n",
    "                    iter_block_items(source), iter_block_items(reference)\n",
    "                ):\n",
    "                    if (\n",
    "                        isinstance(src_block, Paragraph)\n",
    "                        and isinstance(ref_block, Paragraph)\n",
    "                        and src_block.text is not None\n",
    "                        and ref_block.text is not None\n",
    "                    ):\n",
    "                        try:\n",
    "                            tsv_f.write(src_block.text + \"\\t\" + ref_block.text)\n",
    "                            tsv_f.write(\"\\n\")\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                    elif isinstance(src_block, Table) and isinstance(ref_block, Table):\n",
    "                        try:\n",
    "                            for src_row, ref_row in zip(src_block.rows, ref_block.rows):\n",
    "                                src_row_data = []\n",
    "                                ref_row_data = []\n",
    "                                for cell in src_row.cells:\n",
    "                                    for paragraph in cell.paragraphs:\n",
    "                                        src_row_data.append(paragraph.text)\n",
    "                                for cell in ref_row.cells:\n",
    "                                    for paragraph in cell.paragraphs:\n",
    "                                        ref_row_data.append(paragraph.text)\n",
    "                                if len(src_row_data) >= 200 or len(ref_row_data) >= 200:\n",
    "                                    print(\n",
    "                                        \"Length of a pair detected to be greater than 200 words.\"\n",
    "                                    )\n",
    "                                    print(\"this pair will be skipped\")\n",
    "                                    more_than_200_words[\" \".join(src_row_data)] = (\n",
    "                                        \" \".join(ref_row_data)\n",
    "                                    )\n",
    "                                else:\n",
    "                                    tsv_f.write(\n",
    "                                        \" \".join(src_row_data)\n",
    "                                        + \"\\t\"\n",
    "                                        + \" \".join(ref_row_data)\n",
    "                                    )\n",
    "                                    tsv_f.write(\"\\n\")\n",
    "                        except Exceptio as e:\n",
    "                            print(e)\n",
    "                    else:\n",
    "                        try:\n",
    "                            mismatched_block[src_block.text] = ref_block\n",
    "                        except:\n",
    "                            mismatched_block[src_block] = ref_block.text\n",
    "                        break\n",
    "\n",
    "            tsv_f.close()\n",
    "        print(f\"Generated TSV stored at {tsv_file}\")\n",
    "        return mismatched_block, more_than_200_words\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7fc4fe-50dd-439a-931d-aed77ded7053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated TSV stored at /home/jupyter/src/your_tsv_file_name.tsv\n"
     ]
    }
   ],
   "source": [
    "mismatched_block, more_than_200_words = make_tsv(source_ref_dictionary, tsv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040d325e-9ef8-47fd-9bf7-b11c68f208d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatched_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ceb169-ecb0-401d-ab6d-07aa1ebd3b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_200_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a2336-c42a-491c-8eb1-ba7742741cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
