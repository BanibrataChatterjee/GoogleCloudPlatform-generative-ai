{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Debugging and Optimizing Agents: A Guide to Tracing in Reasoning Engine\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Freasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84f0f73a0f76"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Kristopher Overholt](https://github.com/koverholt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview) (LangChain on Vertex AI) is a managed service that helps you to build and deploy an agent reasoning framework. [LangGraph](https://langchain-ai.github.io/langgraph/) is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.\n",
    "\n",
    "## TODO\n",
    "\n",
    "- Update the below info for tracing, LangChain, and Cloud Trace\n",
    "- Add narrative text throughout example / tutorial sections\n",
    "- Switch tools to a different scenario\n",
    "\n",
    "This notebook demonstrates how to use \n",
    "\n",
    "Note that the approach used in this notebook defines a [custom application template in Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/customize), which can be extended to LangChain or other orchestration frameworks. If just want to use LangChain on Vertex AI to build agentic generative AI applications, refer to the documentation for [developing with the LangChain template in Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/develop).\n",
    "\n",
    "This notebook covers the following steps:\n",
    "\n",
    "- **Define Tools**: Create custom Python functions to act as tools your AI application can use.\n",
    "- **Define Router**: Create custom Python functions to act as tools your AI application can use.\n",
    "- **Build a LangGraph Application**: Structure your application using LangGraph, including the Gemini model and custom tools that you define.\n",
    "- **Local Testing**: Test your LangGraph application locally to ensure functionality.\n",
    "- **Deploying to Vertex AI**: Seamlessly deploy your LangGraph application to Reasoning Engine for scalable execution.\n",
    "- **Remote Testing**: Interact with your deployed application through Vertex AI, testing its functionality in a production-like environment.\n",
    "- **Cleaning Up Resources**: Delete your deployed application on Vertex AI to avoid incurring unnecessary charges.\n",
    "\n",
    "By the end of this notebook, you'll have the skills and knowledge to build and deploy your own custom generative AI applications using LangGraph, Reasoning Engine, and Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "### Example trace\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"name\": \"llm\",\n",
    "   \"context\": {\n",
    "       \"trace_id\": \"ed7b336d-e71a-46f0-a334-5f2e87cb6cfc\",\n",
    "       \"span_id\": \"ad67332a-38bd-428e-9f62-538ba2fa90d4\"\n",
    "   },\n",
    "   \"span_kind\": \"LLM\",\n",
    "   \"parent_id\": \"f89ebb7c-10f6-4bf8-8a74-57324d2556ef\",\n",
    "   \"start_time\": \"2023-09-07T12:54:47.597121-06:00\",\n",
    "   \"end_time\": \"2023-09-07T12:54:49.321811-06:00\",\n",
    "   \"status_code\": \"OK\",\n",
    "   \"status_message\": \"\",\n",
    "   \"attributes\": {\n",
    "       \"llm.input_messages\": [\n",
    "           {\n",
    "               \"message.role\": \"system\",\n",
    "               \"message.content\": \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"\n",
    "           },\n",
    "           {\n",
    "               \"message.role\": \"user\",\n",
    "               \"message.content\": \"Hello?\"\n",
    "           }\n",
    "       ],\n",
    "       \"output.value\": \"assistant: Yes I am here\",\n",
    "       \"output.mime_type\": \"text/plain\"\n",
    "   },\n",
    "   \"events\": [],\n",
    "}\n",
    "```\n",
    "\n",
    "### Trace\n",
    "\n",
    "You can think of a [trace](https://opentelemetry.io/docs/concepts/signals/traces/) like a timeline of requests as they travel through your application. A trace is composed of individual spans, with the first span representing the overall request. Each span provides details about a specific operation within the request.\n",
    "\n",
    "### Span\n",
    "\n",
    "A [span](https://opentelemetry.io/docs/concepts/signals/traces/#spans) represents a single unit of work, like a function call or an interaction with an LLM. It captures information such as the operation's name, start and end times, and any relevant attributes (metadata). Spans can be nested, showing parent-child relationships between operations.\n",
    "\n",
    "### Span Attribute\n",
    "\n",
    "[Span attributes](https://opentelemetry.io/docs/concepts/signals/traces/#attributes) are key-value pairs that provide additional context about a span. For instance, an LLM span might have attributes like the model name, prompt text, and token count.\n",
    "\n",
    "### Span Kind\n",
    "\n",
    "[Span kind](https://opentelemetry.io/docs/concepts/signals/traces/#span-kind) categorizes the type of operation a span represents. Common kinds include:\n",
    "\n",
    "- `CHAIN`: Links between LLM application steps or the start of a request.\n",
    "- `LLM`: A call to a large language model.\n",
    "- `TOOL`: An interaction with an external tool (API, database, etc.).\n",
    "- `AGENT`: A reasoning block that combines LLM and tool interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "STAGING_BUCKET = \"gs://[your-staging-bucket]\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet \\\n",
    "    \"google-cloud-aiplatform[langchain,reasoningengine]\" \\\n",
    "    cloudpickle==3.0.0 \\\n",
    "    pydantic==2.7.4 \\\n",
    "    google-cloud-trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "## Build and deploy an agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import trace_v1\n",
    "from vertexai.preview import reasoning_engines\n",
    "from vertexai.reasoning_engines._reasoning_engines import _utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exchange_rate(\n",
    "    currency_from: str = \"USD\",\n",
    "    currency_to: str = \"EUR\",\n",
    "    currency_date: str = \"latest\",\n",
    "):\n",
    "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\n",
    "\n",
    "    Uses the Frankfurter API (https://api.frankfurter.app/) to obtain exchange rate data.\n",
    "\n",
    "    Args:\n",
    "        currency_from: The base currency (3-letter currency code). Defaults to \"USD\" (US Dollar).\n",
    "        currency_to: The target currency (3-letter currency code). Defaults to \"EUR\" (Euro).\n",
    "        currency_date: The date for which to retrieve the exchange rate. Defaults to \"latest\" for the most recent exchange rate data. Can be specified in YYYY-MM-DD format for historical rates.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the exchange rate information.\n",
    "             Example: {\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2023-11-24\", \"rates\": {\"EUR\": 0.95534}}\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    response = requests.get(\n",
    "        f\"https://api.frankfurter.app/{currency_date}\",\n",
    "        params={\"from\": currency_from, \"to\": currency_to},\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define agent and enable tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=\"gemini-1.5-pro-001\",\n",
    "    tools=[get_exchange_rate],\n",
    "    enable_tracing=True,\n",
    "    config={\"metadata\": {\"session\": \"debug-123\"},  # Optional tags to inject into traces\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your agent locally (with traces!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the exchange rate from US dollars to Swedish currency today?\",\n",
       " 'output': 'The exchange rate from US dollars to Swedish krona is 1 USD to 10.61 SEK. \\n'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(\n",
    "    input=\"What's the exchange rate from US dollars to Swedish currency today?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when you're testing your agent locally, you can view the traces for your agent to see details about X, Y, and Z.\n",
    "\n",
    "To view the trace for the query that you just ran:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your first trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = trace_v1.TraceServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [\n",
    "    r for r in client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "        project_id=PROJECT_ID,\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = traces[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_id: \"koverholt-devrel-355716\"\n",
       "trace_id: \"09bf2fa13718976563f1a41cdb5a6359\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [r for r in client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "    project_id=PROJECT_ID,\n",
    "    # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
    "    filter=\"openinference.span.kind:AGENT\"\n",
    "))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = client.get_trace(project_id=PROJECT_ID, trace_id=traces[0].trace_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "span_id: 11469215384998756718\n",
       "name: \"AgentExecutor\"\n",
       "start_time {\n",
       "  seconds: 1719610540\n",
       "  nanos: 944411136\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1719610549\n",
       "  nanos: 372617984\n",
       "}\n",
       "labels {\n",
       "  key: \"output.value\"\n",
       "  value: \"The exchange rate from US dollars to Swedish krona is 1 USD to 10.61 SEK. \\n\"\n",
       "}\n",
       "labels {\n",
       "  key: \"openinference.span.kind\"\n",
       "  value: \"AGENT\"\n",
       "}\n",
       "labels {\n",
       "  key: \"input.value\"\n",
       "  value: \"What\\'s the exchange rate from US dollars to Swedish currency today?\"\n",
       "}\n",
       "labels {\n",
       "  key: \"g.co/agent\"\n",
       "  value: \"opentelemetry-python 1.25.0; google-cloud-trace-exporter 1.6.0\"\n",
       "}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.spans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you deploy your agent and make remote queries in the following sections, you'll dive into the details for working with trace data in the Cloud Console or using the Python SDK for Cloud Trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdGcHqUv8THp"
   },
   "source": [
    "### Deploy your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrTI0_1j8E7w",
    "outputId": "d0386227-e1be-44c1-b40f-b01d926ead32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket koverholt-devrel-355716-bucket\n",
      "Writing to gs://koverholt-devrel-355716-bucket/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://koverholt-devrel-355716-bucket/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://koverholt-devrel-355716-bucket/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/964731510884/locations/us-central1/reasoningEngines/1586287415624990720/operations/1605235058988285952\n",
      "ReasoningEngine created. Resource name: projects/964731510884/locations/us-central1/reasoningEngines/1586287415624990720\n",
      "To use this ReasoningEngine in another session:\n",
      "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/964731510884/locations/us-central1/reasoningEngines/1586287415624990720')\n"
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic==2.7.4\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query your deployed agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZjdFQ_Z_J43",
    "outputId": "18cccdbc-4e40-4c0c-f1b5-42179739d494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the exchange rate from US dollars to Swedish currency?\",\n",
       " 'output': 'The exchange rate is 1 US Dollar to 10.4052 Swedish Krona.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(\n",
    "    input=\"What's the exchange rate from US dollars to Swedish currency?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYwmTcdgIlza"
   },
   "source": [
    "## Exploring traces in the Cloud Console\n",
    "\n",
    "https://cloud.google.com/trace/docs/finding-traces\n",
    "\n",
    "1. For the project `gcp-project`, you can explore the traces using the Cloud Trace Explorer at https://console.cloud.google.com/traces/list?project=gcp-project\n",
    "\n",
    "2. If you have the Trace ID (e.g. `your-trace-id`) for a particular trace, you can view it at https://console.cloud.google.com/traces/list?project=gcp-project&tid=abcd1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with traces using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanId</th>\n",
       "      <th>name</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>labels</th>\n",
       "      <th>parentSpanId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11469215384998756718</td>\n",
       "      <td>AgentExecutor</td>\n",
       "      <td>2024-06-28T21:35:40.944411136Z</td>\n",
       "      <td>2024-06-28T21:35:49.372617984Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1605890896725060040</td>\n",
       "      <td>RunnableSequence</td>\n",
       "      <td>2024-06-28T21:35:40.955333120Z</td>\n",
       "      <td>2024-06-28T21:35:44.654963968Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>11469215384998756718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5360685900019806995</td>\n",
       "      <td>get_exchange_rate</td>\n",
       "      <td>2024-06-28T21:35:44.869442816Z</td>\n",
       "      <td>2024-06-28T21:35:45.742665984Z</td>\n",
       "      <td>{'tool.name': 'get_exchange_rate', 'g.co/agent...</td>\n",
       "      <td>11469215384998756718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16201913772494123770</td>\n",
       "      <td>RunnableParallel&lt;input,agent_scratchpad&gt;</td>\n",
       "      <td>2024-06-28T21:35:45.973032960Z</td>\n",
       "      <td>2024-06-28T21:35:46.231666176Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>16869047450359710008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12176265709676253650</td>\n",
       "      <td>ChatPromptTemplate</td>\n",
       "      <td>2024-06-28T21:35:46.417494016Z</td>\n",
       "      <td>2024-06-28T21:35:46.418998016Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>16869047450359710008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13447144205799117434</td>\n",
       "      <td>RunnableParallel&lt;input,agent_scratchpad&gt;</td>\n",
       "      <td>2024-06-28T21:35:40.957278976Z</td>\n",
       "      <td>2024-06-28T21:35:41.509939968Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>1605890896725060040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12949462071645837552</td>\n",
       "      <td>RunnableLambda</td>\n",
       "      <td>2024-06-28T21:35:40.957742848Z</td>\n",
       "      <td>2024-06-28T21:35:40.958074112Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>13447144205799117434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5639600538414318182</td>\n",
       "      <td>RunnableLambda</td>\n",
       "      <td>2024-06-28T21:35:40.959088128Z</td>\n",
       "      <td>2024-06-28T21:35:40.959360Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>13447144205799117434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10647705944622325788</td>\n",
       "      <td>ChatPromptTemplate</td>\n",
       "      <td>2024-06-28T21:35:41.793710080Z</td>\n",
       "      <td>2024-06-28T21:35:41.795612160Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>1605890896725060040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8581611416918654378</td>\n",
       "      <td>ChatVertexAI</td>\n",
       "      <td>2024-06-28T21:35:42.034980096Z</td>\n",
       "      <td>2024-06-28T21:35:44.138663936Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>1605890896725060040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10863568667540508920</td>\n",
       "      <td>ToolsAgentOutputParser</td>\n",
       "      <td>2024-06-28T21:35:44.415198976Z</td>\n",
       "      <td>2024-06-28T21:35:44.416279040Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>1605890896725060040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16869047450359710008</td>\n",
       "      <td>RunnableSequence</td>\n",
       "      <td>2024-06-28T21:35:45.967067904Z</td>\n",
       "      <td>2024-06-28T21:35:49.202935808Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>11469215384998756718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13600490449451438502</td>\n",
       "      <td>RunnableLambda</td>\n",
       "      <td>2024-06-28T21:35:45.975203072Z</td>\n",
       "      <td>2024-06-28T21:35:45.976413952Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>16201913772494123770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11550272692646785086</td>\n",
       "      <td>RunnableLambda</td>\n",
       "      <td>2024-06-28T21:35:45.976017920Z</td>\n",
       "      <td>2024-06-28T21:35:45.978760960Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>16201913772494123770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1664264463028383759</td>\n",
       "      <td>ChatVertexAI</td>\n",
       "      <td>2024-06-28T21:35:46.753844992Z</td>\n",
       "      <td>2024-06-28T21:35:48.858014208Z</td>\n",
       "      <td>{'llm.input_messages.1.message.role': 'assistant...</td>\n",
       "      <td>16869047450359710008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4373900998777215836</td>\n",
       "      <td>ToolsAgentOutputParser</td>\n",
       "      <td>2024-06-28T21:35:49.027089152Z</td>\n",
       "      <td>2024-06-28T21:35:49.028416Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>16869047450359710008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  spanId                                      name  \\\n",
       "0   11469215384998756718                             AgentExecutor   \n",
       "1    1605890896725060040                          RunnableSequence   \n",
       "2    5360685900019806995                         get_exchange_rate   \n",
       "3   16201913772494123770  RunnableParallel<input,agent_scratchpad>   \n",
       "4   12176265709676253650                        ChatPromptTemplate   \n",
       "5   13447144205799117434  RunnableParallel<input,agent_scratchpad>   \n",
       "6   12949462071645837552                            RunnableLambda   \n",
       "7    5639600538414318182                            RunnableLambda   \n",
       "8   10647705944622325788                        ChatPromptTemplate   \n",
       "9    8581611416918654378                              ChatVertexAI   \n",
       "10  10863568667540508920                    ToolsAgentOutputParser   \n",
       "11  16869047450359710008                          RunnableSequence   \n",
       "12  13600490449451438502                            RunnableLambda   \n",
       "13  11550272692646785086                            RunnableLambda   \n",
       "14   1664264463028383759                              ChatVertexAI   \n",
       "15   4373900998777215836                    ToolsAgentOutputParser   \n",
       "\n",
       "                         startTime                         endTime  \\\n",
       "0   2024-06-28T21:35:40.944411136Z  2024-06-28T21:35:49.372617984Z   \n",
       "1   2024-06-28T21:35:40.955333120Z  2024-06-28T21:35:44.654963968Z   \n",
       "2   2024-06-28T21:35:44.869442816Z  2024-06-28T21:35:45.742665984Z   \n",
       "3   2024-06-28T21:35:45.973032960Z  2024-06-28T21:35:46.231666176Z   \n",
       "4   2024-06-28T21:35:46.417494016Z  2024-06-28T21:35:46.418998016Z   \n",
       "5   2024-06-28T21:35:40.957278976Z  2024-06-28T21:35:41.509939968Z   \n",
       "6   2024-06-28T21:35:40.957742848Z  2024-06-28T21:35:40.958074112Z   \n",
       "7   2024-06-28T21:35:40.959088128Z     2024-06-28T21:35:40.959360Z   \n",
       "8   2024-06-28T21:35:41.793710080Z  2024-06-28T21:35:41.795612160Z   \n",
       "9   2024-06-28T21:35:42.034980096Z  2024-06-28T21:35:44.138663936Z   \n",
       "10  2024-06-28T21:35:44.415198976Z  2024-06-28T21:35:44.416279040Z   \n",
       "11  2024-06-28T21:35:45.967067904Z  2024-06-28T21:35:49.202935808Z   \n",
       "12  2024-06-28T21:35:45.975203072Z  2024-06-28T21:35:45.976413952Z   \n",
       "13  2024-06-28T21:35:45.976017920Z  2024-06-28T21:35:45.978760960Z   \n",
       "14  2024-06-28T21:35:46.753844992Z  2024-06-28T21:35:48.858014208Z   \n",
       "15  2024-06-28T21:35:49.027089152Z     2024-06-28T21:35:49.028416Z   \n",
       "\n",
       "                                               labels          parentSpanId  \n",
       "0   {'g.co/agent': 'opentelemetry-python 1.25.0; g...                   NaN  \n",
       "1   {'g.co/agent': 'opentelemetry-python 1.25.0; g...  11469215384998756718  \n",
       "2   {'tool.name': 'get_exchange_rate', 'g.co/agent...  11469215384998756718  \n",
       "3   {'g.co/agent': 'opentelemetry-python 1.25.0; g...  16869047450359710008  \n",
       "4   {'g.co/agent': 'opentelemetry-python 1.25.0; g...  16869047450359710008  \n",
       "5   {'g.co/agent': 'opentelemetry-python 1.25.0; g...   1605890896725060040  \n",
       "6   {'g.co/agent': 'opentelemetry-python 1.25.0; g...  13447144205799117434  \n",
       "7   {'g.co/agent': 'opentelemetry-python 1.25.0; g...  13447144205799117434  \n",
       "8   {'g.co/agent': 'opentelemetry-python 1.25.0; g...   1605890896725060040  \n",
       "9   {'g.co/agent': 'opentelemetry-python 1.25.0; g...   1605890896725060040  \n",
       "10  {'g.co/agent': 'opentelemetry-python 1.25.0; g...   1605890896725060040  \n",
       "11  {'g.co/agent': 'opentelemetry-python 1.25.0; g...  11469215384998756718  \n",
       "12  {'g.co/agent': 'opentelemetry-python 1.25.0; g...  16201913772494123770  \n",
       "13  {'g.co/agent': 'opentelemetry-python 1.25.0; g...  16201913772494123770  \n",
       "14  {'llm.input_messages.1.message.role': 'assistant...  16869047450359710008  \n",
       "15  {'g.co/agent': 'opentelemetry-python 1.25.0; g...  16869047450359710008  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = pd.DataFrame.from_records([_utils.to_dict(span) for span in trace.spans])\n",
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanId</th>\n",
       "      <th>name</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>labels</th>\n",
       "      <th>parentSpanId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8581611416918654378</td>\n",
       "      <td>ChatVertexAI</td>\n",
       "      <td>2024-06-28T21:35:42.034980096Z</td>\n",
       "      <td>2024-06-28T21:35:44.138663936Z</td>\n",
       "      <td>{'g.co/agent': 'opentelemetry-python 1.25.0; g...</td>\n",
       "      <td>1605890896725060040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1664264463028383759</td>\n",
       "      <td>ChatVertexAI</td>\n",
       "      <td>2024-06-28T21:35:46.753844992Z</td>\n",
       "      <td>2024-06-28T21:35:48.858014208Z</td>\n",
       "      <td>{'llm.input_messages.1.message.role': 'assistant...</td>\n",
       "      <td>16869047450359710008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 spanId          name                       startTime  \\\n",
       "9   8581611416918654378  ChatVertexAI  2024-06-28T21:35:42.034980096Z   \n",
       "14  1664264463028383759  ChatVertexAI  2024-06-28T21:35:46.753844992Z   \n",
       "\n",
       "                           endTime  \\\n",
       "9   2024-06-28T21:35:44.138663936Z   \n",
       "14  2024-06-28T21:35:48.858014208Z   \n",
       "\n",
       "                                               labels          parentSpanId  \n",
       "9   {'g.co/agent': 'opentelemetry-python 1.25.0; g...   1605890896725060040  \n",
       "14  {'llm.input_messages.1.message.role': 'assistant...  16869047450359710008  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[spans[\"name\"] == \"ChatVertexAI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g.co/agent</th>\n",
       "      <th>llm.invocation_parameters</th>\n",
       "      <th>output.mime_type</th>\n",
       "      <th>llm.output_messages.0.message.function_call_arguments_json</th>\n",
       "      <th>llm.input_messages.0.message.content</th>\n",
       "      <th>output.value</th>\n",
       "      <th>llm.input_messages.0.message.role</th>\n",
       "      <th>input.mime_type</th>\n",
       "      <th>input.value</th>\n",
       "      <th>llm.output_messages.0.message.function_call_name</th>\n",
       "      <th>openinference.span.kind</th>\n",
       "      <th>llm.model_name</th>\n",
       "      <th>llm.function_call</th>\n",
       "      <th>llm.output_messages.0.message.role</th>\n",
       "      <th>llm.input_messages.1.message.role</th>\n",
       "      <th>llm.input_messages.2.message.role</th>\n",
       "      <th>llm.input_messages.1.message.function_call_arguments_json</th>\n",
       "      <th>llm.input_messages.2.message.content</th>\n",
       "      <th>llm.output_messages.0.message.content</th>\n",
       "      <th>llm.input_messages.1.message.function_call_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>opentelemetry-python 1.25.0; google-cloud-trac...</td>\n",
       "      <td>{\"model_name\": \"gemini-1.5-pro-001\", \"candidate...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"currency_from\": \"USD\", \"currency_to\": \"SEK\"}</td>\n",
       "      <td>What's the exchange rate from US dollars to Sw...</td>\n",
       "      <td>{\"generations\": [[{\"text\": \"\", \"generation_inf...</td>\n",
       "      <td>user</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"messages\": [[{\"lc\": 1, \"type\": \"constructor\"...</td>\n",
       "      <td>get_exchange_rate</td>\n",
       "      <td>LLM</td>\n",
       "      <td>gemini-1.5-pro-001</td>\n",
       "      <td>{\"name\": \"get_exchange_rate\", \"arguments\": {\"c...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>opentelemetry-python 1.25.0; google-cloud-trac...</td>\n",
       "      <td>{\"model_name\": \"gemini-1.5-pro-001\", \"candidate...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's the exchange rate from US dollars to Sw...</td>\n",
       "      <td>{\"generations\": [[{\"text\": \"The exchange rate ...</td>\n",
       "      <td>user</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"messages\": [[{\"lc\": 1, \"type\": \"constructor\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLM</td>\n",
       "      <td>gemini-1.5-pro-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assistant</td>\n",
       "      <td>assistant</td>\n",
       "      <td>tool</td>\n",
       "      <td>{\"currency_from\": \"USD\", \"currency_to\": \"SEK\"}</td>\n",
       "      <td>{\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2024-0...</td>\n",
       "      <td>The exchange rate from US dollars to Swedish k...</td>\n",
       "      <td>get_exchange_rate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           g.co/agent  \\\n",
       "9   opentelemetry-python 1.25.0; google-cloud-trac...   \n",
       "14  opentelemetry-python 1.25.0; google-cloud-trac...   \n",
       "\n",
       "                            llm.invocation_parameters  output.mime_type  \\\n",
       "9   {\"model_name\": \"gemini-1.5-pro-001\", \"candidate...  application/json   \n",
       "14  {\"model_name\": \"gemini-1.5-pro-001\", \"candidate...  application/json   \n",
       "\n",
       "   llm.output_messages.0.message.function_call_arguments_json  \\\n",
       "9      {\"currency_from\": \"USD\", \"currency_to\": \"SEK\"}           \n",
       "14                                                NaN           \n",
       "\n",
       "                 llm.input_messages.0.message.content  \\\n",
       "9   What's the exchange rate from US dollars to Sw...   \n",
       "14  What's the exchange rate from US dollars to Sw...   \n",
       "\n",
       "                                         output.value  \\\n",
       "9   {\"generations\": [[{\"text\": \"\", \"generation_inf...   \n",
       "14  {\"generations\": [[{\"text\": \"The exchange rate ...   \n",
       "\n",
       "   llm.input_messages.0.message.role   input.mime_type  \\\n",
       "9                               user  application/json   \n",
       "14                              user  application/json   \n",
       "\n",
       "                                          input.value  \\\n",
       "9   {\"messages\": [[{\"lc\": 1, \"type\": \"constructor\"...   \n",
       "14  {\"messages\": [[{\"lc\": 1, \"type\": \"constructor\"...   \n",
       "\n",
       "   llm.output_messages.0.message.function_call_name openinference.span.kind  \\\n",
       "9                                 get_exchange_rate                     LLM   \n",
       "14                                              NaN                     LLM   \n",
       "\n",
       "        llm.model_name                                  llm.function_call  \\\n",
       "9   gemini-1.5-pro-001  {\"name\": \"get_exchange_rate\", \"arguments\": {\"c...   \n",
       "14  gemini-1.5-pro-001                                                NaN   \n",
       "\n",
       "   llm.output_messages.0.message.role llm.input_messages.1.message.role  \\\n",
       "9                           assistant                               NaN   \n",
       "14                          assistant                         assistant   \n",
       "\n",
       "   llm.input_messages.2.message.role  \\\n",
       "9                                NaN   \n",
       "14                              tool   \n",
       "\n",
       "   llm.input_messages.1.message.function_call_arguments_json  \\\n",
       "9                                                 NaN          \n",
       "14     {\"currency_from\": \"USD\", \"currency_to\": \"SEK\"}          \n",
       "\n",
       "                 llm.input_messages.2.message.content  \\\n",
       "9                                                 NaN   \n",
       "14  {\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2024-0...   \n",
       "\n",
       "                llm.output_messages.0.message.content  \\\n",
       "9                                                 NaN   \n",
       "14  The exchange rate from US dollars to Swedish k...   \n",
       "\n",
       "   llm.input_messages.1.message.function_call_name  \n",
       "9                                              NaN  \n",
       "14                               get_exchange_rate  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[spans[\"name\"] == \"ChatVertexAI\"].labels.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring traces with the Python SDK for Cloud Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "    project_id=PROJECT_ID,\n",
    "    start_time=\"2024-06-10T00:00:00Z\", # optional\n",
    "    end_time=\"2024-06-14T23:59:59Z\", # optional\n",
    "))\n",
    "\n",
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "    project_id=PROJECT_ID,\n",
    "    # Return traces where any root span's name starts with AgentExecutor\n",
    "    filter=\"root:AgentExecutor\"\n",
    ")):\n",
    "\n",
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by view type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "    project_id=PROJECT_ID,\n",
    "    view=trace_v1.types.ListTracesRequest.ViewType.ROOTSPAN,\n",
    "    # view=trace_v1.types.ListTracesRequest.ViewType.MINIMAL,\n",
    "    # view=trace_v1.types.ListTracesRequest.ViewType.COMPLETE,\n",
    ")):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = client.get_trace(project_id=PROJECT_ID, trace_id=\"9dd0c06e88bda06b197b5eff0409e8f9\")\n",
    "\n",
    "trace.project_id, trace.trace_id\n",
    "\n",
    "traces = [\n",
    "    r for r in client.list_traces(request=trace_v1.types.ListTracesRequest(\n",
    "        project_id=PROJECT_ID,\n",
    "        start_time=\"2024-06-10T00:00:00Z\",\n",
    "        end_time=\"2024-06-14T23:59:59Z\",\n",
    "        view=trace_v1.types.ListTracesRequest.ViewType.COMPLETE,\n",
    "    ))\n",
    "]\n",
    "\n",
    "traces[0] # Show just the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_app.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
