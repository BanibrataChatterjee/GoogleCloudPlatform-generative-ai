{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvrjsharma/AI_workflows/blob/main/gemini_pro_and_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JPBuGHaCZ4Bz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install gradio==4.1.1 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yEjiKfMQe_EE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio_multimodalchatbot -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XYn-fc5ueQCw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import PIL.Image\n",
        "from gradio.data_classes import FileData\n",
        "from gradio_multimodalchatbot import MultimodalChatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EvD8Xk9Q_BwY"
      },
      "outputs": [],
      "source": [
        "# For better security practices, retrieve sensitive information like API keys from environment variables.\n",
        "# Set an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"enter-your-google-gemini-API-key-here\"\n",
        "\n",
        "# Fetch an environment variable.\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D28l_sYSkHq7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"candidates\": [\n",
            "    {\n",
            "      \"output\": \"Once upon a time, there was a boy named Billy who found a magic backpack. The backpack could hold anything Billy wanted, and it would always be there when he needed it. Billy used the backpack to help people in need. He would give food to the hungry, clothes to the homeless, and even medical supplies to those in need. Billy's magic backpack made him a hero to everyone who knew him.\",\n",
            "      \"safetyRatings\": [\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_DEROGATORY\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_TOXICITY\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_VIOLENCE\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_SEXUAL\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_MEDICAL\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Verify if your api key is correct or not\n",
        "!curl \\\n",
        "-H 'Content-Type: application/json' \\\n",
        "-d '{ \"prompt\": { \"text\": \"Write a very short story about a magic backpack\"} }' \\\n",
        "\"https://generativelanguage.googleapis.com/v1beta3/models/text-bison-001:generateText?key=<enter-your-key-here>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NqaMuDdexx3n"
      },
      "outputs": [],
      "source": [
        "# Initialize genai models\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "modelvis = genai.GenerativeModel(\"gemini-pro-vision\")\n",
        "\n",
        "\n",
        "def gemini(input, file, chatbot=[]):\n",
        "    \"\"\"\n",
        "    Function to handle gemini model and gemini vision model interactions.\n",
        "\n",
        "    Parameters:\n",
        "    input (str): The input text.\n",
        "    file (File): An optional file object for image processing.\n",
        "    chatbot (list): A list to keep track of chatbot interactions.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Updated chatbot interaction list, an empty string, and None.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = []\n",
        "    print(chatbot)\n",
        "\n",
        "    # Process previous chatbot messages if present\n",
        "    if len(chatbot) != 0:\n",
        "        for user, bot in chatbot:\n",
        "            user, bot = user.text, bot.text\n",
        "            messages.extend(\n",
        "                [{\"role\": \"user\", \"parts\": [user]}, {\"role\": \"model\", \"parts\": [bot]}]\n",
        "            )\n",
        "        messages.append({\"role\": \"user\", \"parts\": [input]})\n",
        "    else:\n",
        "        messages.append({\"role\": \"user\", \"parts\": [input]})\n",
        "\n",
        "    try:\n",
        "        # Process image if file is provided\n",
        "        if file is not None:\n",
        "            with PIL.Image.open(file.name) as img:\n",
        "                message = [{\"role\": \"user\", \"parts\": [input, img]}]\n",
        "                response = modelvis.generate_content(message)\n",
        "                gemini_video_resp = response.text\n",
        "                messages.append({\"role\": \"model\", \"parts\": [gemini_video_resp]})\n",
        "\n",
        "                # Construct list of messages in the required format\n",
        "                user_msg = {\n",
        "                    \"text\": input,\n",
        "                    \"files\": [{\"file\": FileData(path=file.name)}],\n",
        "                }\n",
        "                bot_msg = {\"text\": gemini_video_resp, \"files\": []}\n",
        "                chatbot.append([user_msg, bot_msg])\n",
        "        else:\n",
        "            response = model.generate_content(messages)\n",
        "            gemini_resp = response.text\n",
        "\n",
        "            # Construct list of messages in the required format\n",
        "            user_msg = {\"text\": input, \"files\": []}\n",
        "            bot_msg = {\"text\": gemini_resp, \"files\": []}\n",
        "            chatbot.append([user_msg, bot_msg])\n",
        "    except Exception as e:\n",
        "        # Handling exceptions and raising error to the modal\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        raise gr.Error(e)\n",
        "\n",
        "    return chatbot, \"\", None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kf6QH-tl4ShY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:889: UserWarning: api_name lambda already exists, using lambda_1\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:889: UserWarning: api_name lambda already exists, using lambda_2\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://ee733f7aff825581f2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ee733f7aff825581f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[(MultimodalMessage(text='hi', files=[]), MultimodalMessage(text='Hello! How can I help you today?', files=[]))]\n",
            "[(MultimodalMessage(text='hi', files=[]), MultimodalMessage(text='Hello! How can I help you today?', files=[])), (MultimodalMessage(text='explain the image?', files=[FileMessage(file=FileData(path='/tmp/gradio/738002faf37e5e07cf5704777d0476aee29f5140/ref4.png', url='https://ee733f7aff825581f2.gradio.live/file=/tmp/gradio/738002faf37e5e07cf5704777d0476aee29f5140/ref4.png', size=None, orig_name=None, mime_type='image/png'), alt_text=None)]), MultimodalMessage(text='The image shows an ancient Assyrian relief carving. The carving depicts a king or other high-ranking official standing before a group of people. The king is holding a staff or scepter in one hand and a box or other object in the other hand. The people before him are standing in various poses and appear to be listening to the king or official. The carving is finely detailed and provides a glimpse into the art and culture of ancient Assyria.', files=[]))]\n",
            "[(MultimodalMessage(text='hi', files=[]), MultimodalMessage(text='Hello! How can I help you today?', files=[])), (MultimodalMessage(text='explain the image?', files=[FileMessage(file=FileData(path='/tmp/gradio/00047e04ea66e74b566ec36dfde3bd13c2fa10ab/ref4.png', url='https://ee733f7aff825581f2.gradio.live/file=/tmp/gradio/738002faf37e5e07cf5704777d0476aee29f5140/ref4.png', size=None, orig_name=None, mime_type='image/png'), alt_text=None)]), MultimodalMessage(text='The image shows an ancient Assyrian relief carving. The carving depicts a king or other high-ranking official standing before a group of people. The king is holding a staff or scepter in one hand and a box or other object in the other hand. The people before him are standing in various poses and appear to be listening to the king or official. The carving is finely detailed and provides a glimpse into the art and culture of ancient Assyria.', files=[])), (MultimodalMessage(text='tell me a joke related to what was there in the image', files=[]), MultimodalMessage(text=\"Why did the ancient Assyrian king cross the river?\\n\\nTo get to the other side of the empire!\\n\\n(Okay, that was a bit of a corny joke, but I couldn't resist.)\", files=[]))]\n",
            "[(MultimodalMessage(text='hi', files=[]), MultimodalMessage(text='Hello! How can I help you today?', files=[])), (MultimodalMessage(text='explain the image?', files=[FileMessage(file=FileData(path='/tmp/gradio/00047e04ea66e74b566ec36dfde3bd13c2fa10ab/ref4.png', url='https://ee733f7aff825581f2.gradio.live/file=/tmp/gradio/738002faf37e5e07cf5704777d0476aee29f5140/ref4.png', size=None, orig_name=None, mime_type='image/png'), alt_text=None)]), MultimodalMessage(text='The image shows an ancient Assyrian relief carving. The carving depicts a king or other high-ranking official standing before a group of people. The king is holding a staff or scepter in one hand and a box or other object in the other hand. The people before him are standing in various poses and appear to be listening to the king or official. The carving is finely detailed and provides a glimpse into the art and culture of ancient Assyria.', files=[])), (MultimodalMessage(text='tell me a joke related to what was there in the image', files=[]), MultimodalMessage(text=\"Why did the ancient Assyrian king cross the river?\\n\\nTo get to the other side of the empire!\\n\\n(Okay, that was a bit of a corny joke, but I couldn't resist.)\", files=[]))]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ee733f7aff825581f2.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the Gradio Blocks interface\n",
        "with gr.Blocks() as demo:\n",
        "    # Add a centered header using HTML\n",
        "    gr.HTML(\"<center><h1>Gemini-PRO & Gemini-PRO-Vision API</h1></center>\")\n",
        "\n",
        "    # Initialize the MultimodalChatbot component\n",
        "    multi = MultimodalChatbot(value=[], height=800)\n",
        "\n",
        "    with gr.Row():\n",
        "        # Textbox for user input with increased scale for better visibility\n",
        "        tb = gr.Textbox(scale=4)\n",
        "\n",
        "        # Upload button for image files\n",
        "        up = gr.UploadButton(\"Upload Image\", file_types=[\"image\"], scale=1)\n",
        "\n",
        "    # Define the behavior on text submission\n",
        "    tb.submit(gemini, [tb, up, multi], [multi, tb, up])\n",
        "\n",
        "    # Define the behavior on image upload\n",
        "    # Using chained then() calls to update the upload button's state\n",
        "    up.upload(lambda: gr.UploadButton(\"Uploading Image...\"), [], up).then(\n",
        "        lambda: gr.UploadButton(\"Image Uploaded\"), [], up\n",
        "    ).then(lambda: gr.UploadButton(\"Upload Image\"), [], up)\n",
        "\n",
        "# Launch the demo with a queue to handle multiple users\n",
        "demo.queue().launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "gemini_pro_and_vision.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
