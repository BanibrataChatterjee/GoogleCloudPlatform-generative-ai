{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bCIMTPB1WoTq"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPmcMNgZpo9V"
      },
      "source": [
        "# Analyze a codebase with the Vertex AI Gemini 1.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fcode%2Fanalyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/code/analyze_codebase_with_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EExYZvij2ve"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Eric Dong](https://github.com/gericdong), [Aakash Gouda](https://github.com/aksstar)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVV6txOmNMn"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Gemini 1.5 Pro introduces a breakthrough long context window of up to 1 million tokens that can help seamlessly analyze, classify and summarize large amounts of content within a given prompt. With its long-context reasoning, Gemini 1.5 Pro can analyze an entire codebase for deeper insights.\n",
        "\n",
        "In this tutorial, you learn how to analyze an entire codebase with Gemini 1.5 Pro and prompt the model to:\n",
        "\n",
        "- **Analyze**: Summarize codebases effortlessly.\n",
        "- **Guide**: Generate clear developer getting-started documentation.\n",
        "- **Debug**: Uncover critical bugs and provide fixes.\n",
        "- **Enhance**: Implement new features and improve reliability and security.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdMGtr18rFdL"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script dotenv is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script f2py is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script magika is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform \\\n",
        "                                        gitpython \\\n",
        "                                        magika"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbozY-XKee95"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NSCFmvOWBas9"
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from vertexai.generative_models import (FunctionDeclaration, GenerativeModel,\n",
        "                                        Tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNoOTMp2fe33"
      },
      "source": [
        "## Cloning a codebase\n",
        "\n",
        "You will use repo [Online Boutique](https://github.com/GoogleCloudPlatform/microservices-demo) as an example in this notebook. Online Boutique is a cloud-first microservices demo application. The application is a web-based e-commerce app where users can browse items, add them to the cart, and purchase them. This application consists of 11 microservices across multiple languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GlDOs49qgStM"
      },
      "outputs": [],
      "source": [
        "# The GitHub repository URL\n",
        "repo_url = \"https://github.com/GoogleCloudPlatform/microservices-demo\"  # @param {type:\"string\"}\n",
        "\n",
        "# The location to clone the repo\n",
        "repo_dir = \"./repo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAm1ly9pfIEX"
      },
      "source": [
        "#### Define helper functions for processing Github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "stNia6UaHau2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import git\n",
        "import magika\n",
        "import requests\n",
        "\n",
        "m = magika.Magika()\n",
        "\n",
        "\n",
        "def clone_repo(repo_url, repo_dir):\n",
        "    \"\"\"Clone a GitHub repository.\"\"\"\n",
        "\n",
        "    if os.path.exists(repo_dir):\n",
        "        shutil.rmtree(repo_dir)\n",
        "    os.makedirs(repo_dir)\n",
        "    git.Repo.clone_from(repo_url, repo_dir)\n",
        "\n",
        "\n",
        "def extract_code(repo_dir):\n",
        "    \"\"\"Create an index, extract content of code/text files.\"\"\"\n",
        "\n",
        "    code_index = []\n",
        "    code_text = \"\"\n",
        "    for root, _, files in os.walk(repo_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            relative_path = os.path.relpath(file_path, repo_dir)\n",
        "            code_index.append(relative_path)\n",
        "\n",
        "            file_type = m.identify_path(Path(file_path))\n",
        "            if file_type.output.group in (\"text\", \"code\"):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as f:\n",
        "                        code_text += f\"----- File: {relative_path} -----\\n\"\n",
        "                        code_text += f.read()\n",
        "                        code_text += \"\\n-------------------------\\n\"\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    return code_index, code_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1UyVuQLuTKE"
      },
      "source": [
        "#### Create an index and extract content of a codebase\n",
        "\n",
        "Clone the repo and create an index and extract content of code/text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rqaYzmNQuTKQ"
      },
      "outputs": [],
      "source": [
        "clone_repo(repo_url, repo_dir)\n",
        "\n",
        "code_index, code_text = extract_code(repo_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiVQB5SKekS0"
      },
      "source": [
        "## Analyzing the codebase with Gemini 1.5 Pro\n",
        "\n",
        "With its long-context reasoning, Gemini 1.5 Pro can process the codebase and answer questions about the codebase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "#### Load the Gemini 1.5 Pro model\n",
        "\n",
        "Learn more about the [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vB9gY3WruzK9"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-1.5-pro-preview-0409\"  # @param {type:\"string\"}\n",
        "\n",
        "model = GenerativeModel(\n",
        "    MODEL_ID,\n",
        "    system_instruction=[\n",
        "        \"You are a coding expert.\",\n",
        "        \"Your mission is to answer all code related questions with given context and instructions.\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yedKsUEEvNyb"
      },
      "source": [
        "#### Define a helper function to generate a prompt to a code related question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1DGzMhjCvCpj"
      },
      "outputs": [],
      "source": [
        "def get_code_prompt(question):\n",
        "    \"\"\"Generates a prompt to a code related question.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Questions: {question}\n",
        "\n",
        "    Context:\n",
        "    - The entire codebase is provided below.\n",
        "    - Here is an index of all of the files in the codebase:\n",
        "      \\n\\n{code_index}\\n\\n.\n",
        "    - Then each of the files is concatenated together. You will find all of the code you need:\n",
        "      \\n\\n{code_text}\\n\\n\n",
        "\n",
        "    Answer:\n",
        "  \"\"\"\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3OtaszvJt9L"
      },
      "source": [
        "### 1. Summarizing the codebase\n",
        "\n",
        "\n",
        "Generate a summary of the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMexx1Qtf1ML"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Give me a summary of this codebase, and tell me the top 3 things that I can learn from it.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "# Generate text using non-streaming method\n",
        "response = model.generate_content(contents)\n",
        "\n",
        "# Print generated text and usage metadata\n",
        "print(f\"\\nAnswer:\\n{response.text}\")\n",
        "print(f'\\nUsage metadata:\\n{response.to_dict().get(\"usage_metadata\")}')\n",
        "print(f\"\\nFinish reason:\\n{response.candidates[0].finish_reason}\")\n",
        "print(f\"\\nSafety settings:\\n{response.candidates[0].safety_ratings}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCshJHPCYoxI"
      },
      "source": [
        "### 2. Creating a developer getting started guide\n",
        "\n",
        "Generate a getting started guide for developers. This sample uses the streaming option to generate the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6Kns7vCYm1P"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Provide a getting started guide to onboard new developers to the codebase.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXurINu-jelb"
      },
      "source": [
        "### 3. Finding bugs\n",
        "\n",
        "Find the top 3 most severe issues in the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy3AWPRgNhu_"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Find the top 3 most severe issues in the codebase.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCilrR6FjmfB"
      },
      "source": [
        "### 4. Fixing bug\n",
        "\n",
        "Find the most severe issue in the codebase that can be fixed and provide a code fix for it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwjDh0xGKE2r"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Find the most severe bug in the codebase that you can provide a code fix for.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w2pCULT_xKE"
      },
      "source": [
        "### 5. Implementing a feature request using Function Calling\n",
        "Generate code to implement a feature request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMjOy0gJ1_xx"
      },
      "outputs": [],
      "source": [
        "# Function declaration with detailed docstring\n",
        "extract_details_from_url_func = FunctionDeclaration(\n",
        "    name=\"extract_details_from_url\",\n",
        "    description=\"Extracts owner, repository name, and issue number details from a GitHub issue URL\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"owner\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The owner of the GitHub repository.\",\n",
        "            },\n",
        "            \"repo\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the GitHub repository.\",\n",
        "            },\n",
        "            \"issue_number\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The issue number to fetch the body of.\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Tool definition\n",
        "extraction_tool = Tool(function_declarations=[extract_details_from_url_func])\n",
        "\n",
        "# Feature request URL\n",
        "FEATURE_REQUEST_URL = (\n",
        "    \"https://github.com/GoogleCloudPlatform/microservices-demo/issues/2205\"\n",
        ")\n",
        "\n",
        "# Prompt content\n",
        "prompt_content = f\"What is the feature request of the following {FEATURE_REQUEST_URL}\"\n",
        "\n",
        "# Model generation with tool usage\n",
        "response = model.generate_content(\n",
        "    [prompt_content], generation_config={\"temperature\": 0}, tools=[extraction_tool]\n",
        ")\n",
        "\n",
        "# Extract parameters from model response\n",
        "params = {}\n",
        "for key, value in response.candidates[0].content.parts[0].function_call.args.items():\n",
        "    params[key] = value\n",
        "\n",
        "# Fetch issue details from GitHub API if function call matches\n",
        "if (\n",
        "    response.candidates[0].content.parts[0].function_call.name\n",
        "    == \"extract_details_from_url\"\n",
        "):\n",
        "    headers = {\n",
        "        \"Accept\": \"application/vnd.github+json\",\n",
        "        \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    }  # Set headers for GitHub API\n",
        "\n",
        "    # Construct API URL\n",
        "    url = f\"https://api.github.com/repos/{params['owner']}/{params['repo']}/issues/{params['issue_number']}\"\n",
        "\n",
        "    try:\n",
        "        response_git = requests.get(url, headers=headers)\n",
        "        response_git.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "        issue_data = response_git.json()\n",
        "        if issue_data:\n",
        "            print(\"Feature Request is: \", issue_data[\"body\"])\n",
        "\n",
        "            # Combine feature request with URL and get code prompt\n",
        "            question = (\n",
        "                \"Implement the following feature request\"\n",
        "                + FEATURE_REQUEST_URL\n",
        "                + \"\\n\"\n",
        "                + issue_data[\"body\"]\n",
        "            )\n",
        "            prompt = get_code_prompt(question)\n",
        "            contents = [prompt]\n",
        "\n",
        "            # Generate code response\n",
        "            responses = model.generate_content(contents, stream=True)\n",
        "            for response in responses:\n",
        "                IPython.display.Markdown(response.text)  # Display in Markdown format\n",
        "\n",
        "    except requests.exceptions.RequestException as error:\n",
        "        print(f\"Error fetching issue: {error}\")  # Handle potential errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOk_Qe35b_cJ"
      },
      "source": [
        "### 6. Creating a troubleshooting guide\n",
        "\n",
        "Create a troubleshooting guide to help resolve common issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKn85LS-v0iw"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "    Provide a troubleshooting guide to help resolve common issues.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h23z0sTsj5pL"
      },
      "source": [
        "### 7. Making the app more reliable\n",
        "\n",
        "Recommend best practices to make the application more reliable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOBSulTPLUAo"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  How can I make this application more reliable? Consider best practices from https://www.r9y.dev/\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf1jNDpJj8u0"
      },
      "source": [
        "### 8. Making the app more secure\n",
        "\n",
        "Recommend best practices to make the application more secure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_mCyFVLlXU"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  How can you secure the application?\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFfwMOb6kYfw"
      },
      "source": [
        "### 9. Learning the codebase\n",
        "\n",
        "Create a quiz about the concepts used in the codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7jQIUwsNRH4"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Create a quiz about the concepts used in my codebase to help me solidify my understanding.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjo1UrZwGLan"
      },
      "source": [
        "### 10. Creating a quickstart tutorial\n",
        "\n",
        "Create an end-to-end quickstart tutorial for a specific component.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRwmRyDDFRMB"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "  Please write an end-to-end quickstart tutorial that introduces AlloyDB,\n",
        "  shows how to configure it with the CartService,\n",
        "  and highlights key capabilities of AlloyDB in context of the Online Boutique application.\n",
        "\"\"\"\n",
        "\n",
        "prompt = get_code_prompt(question)\n",
        "contents = [prompt]\n",
        "\n",
        "responses = model.generate_content(contents, stream=True)\n",
        "for response in responses:\n",
        "    IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAJ-kBCZnlH_"
      },
      "source": [
        "### 11. Creating a Git Changelog Generator\n",
        "Understanding changes made between Git commits and highlighting the most important aspects of the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdeWO8crnlH_"
      },
      "outputs": [],
      "source": [
        "# Fetches commit IDs from a local Git repository on a specified branch.\n",
        "\n",
        "repo = git.Repo(repo_dir)\n",
        "branch_name = \"main\"\n",
        "commits = list(repo.iter_commits(branch_name))\n",
        "commit_ids = [\n",
        "    commit.hexsha for commit in commits\n",
        "]  # A list of commit IDs (SHA-1 hashes) in reverse chronological order (newest first)\n",
        "\n",
        "if len(commit_ids) >= 2:\n",
        "    diff_text = repo.git.diff(commit_ids[0], commit_ids[1])\n",
        "\n",
        "    question = \"\"\"\n",
        "      Given the above git diff output, Summarize the important changes made.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = question + code_text\n",
        "    contents = [prompt]\n",
        "\n",
        "    responses = model.generate_content(contents, stream=True)\n",
        "    for response in responses:\n",
        "        IPython.display.Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kUeIBfGyoX7"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, you've learned how to use the Gemini 1.5 Pro to analyze a codebase and prompt the model to:\n",
        "\n",
        "- Summarize codebases effortlessly.\n",
        "- Generate clear developer getting-started documentation.\n",
        "- Uncover critical bugs and provide fixes.\n",
        "- Implement new features and improve reliability and security.\n",
        "- Understanding changes made between Git commits"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "analyze_codebase_with_gemini_1_5_pro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
