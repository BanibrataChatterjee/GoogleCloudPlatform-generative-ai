{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hztiLWXYHkhZ"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tZ0mZ5Hg8_M"
   },
   "source": [
    "# Evaluating prompts at scale with Gemini Batch Prediction API\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fevaluation%2Fevaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T90FYh6-htfF"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Ariel Jassan](https://github.com/arieljassan) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKSYzhrTOCBG"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial guides you through the process of evaluating the effectiveness of your prompts at scale using the Gemini Batch Prediction API. Even though in this tutorial we will do image classification, it can be extended to other cases as well. One of the benefits of using the Gemini Batch Prediction API is that you can evaluate your prompts and setup in Gemini using hundreds of examples with one single request.\n",
    "\n",
    "For the purpose of this tutorial, we will execute a prompt to classify images into classes of sports. The data is based on an excerpt of the datase that can be found in https://www.kaggle.com/datasets/gpiosenka/sports-classification.\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Prepare the data in BigQuery and GCS**\n",
    "    * Upload sample images to Google Cloud Storage and create ground truth table in BigQuery.\n",
    "    \n",
    "2. **Run Gemini Batch Prediciton API**\n",
    "    * Send prompts to Gemini for batch prediction and get results in BigQuery.\n",
    "\n",
    "3. **Analyze results in BigQuery and Looker Studio**\n",
    "    * Present findings, focusing on prompt/dataset strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQX5j8RYJEXs"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOgj6IyiJVkV"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sCnE9GIUkts",
    "outputId": "019a3d3a-ddeb-425e-f9b3-62efd07938fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install google-cloud-aiplatform --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9nGCMsxJZ_v"
   },
   "source": [
    "### Restart Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIWOo23oVGmV",
    "outputId": "c4f6cf20-894d-45ef-9837-7c4c0e0f864a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will see a notification of Colab crashing. It is the expected behavior.\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_Z7Y63KJelC"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UV7jgeu9VImB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-FTvlzlJ8lY"
   },
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "HDVVYzTISvGv"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"your-project-id\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# Generative model.\n",
    "MODEL_ID = \"gemini-1.5-flash-001\"\n",
    "\n",
    "# BigQuery tables.\n",
    "BQ_DATASET_ID = \"text_extraction_3\"\n",
    "BQ_DATASET = f\"{PROJECT_ID}.{BQ_DATASET_ID}\"\n",
    "FILES_TABLE = f\"{BQ_DATASET_ID}.sports_files\"\n",
    "PROMPTS_TABLE = f\"{BQ_DATASET}.temp_prompts\"\n",
    "TEXT_GENERATION_TABLE_PREFIX = f\"{BQ_DATASET}.results\"\n",
    "\n",
    "# BigQuery views.\n",
    "RESULTS_VIEW = f\"{BQ_DATASET}.extraction_results\"\n",
    "EVALUATION_VIEW = f\"{BQ_DATASET}.evaluation\"\n",
    "\n",
    "# GCS Bucket.\n",
    "BUCKET_NAME = \"your-bucket-name\"\n",
    "SPORTS_FILE = f\"gs://{BUCKET_NAME}/sports_files.csv\"\n",
    "\n",
    "# Stop states from .\n",
    "STOP_STATES = (\"JOB_STATE_SUCCEEDED\", \"JOB_STATE_FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WePqYxwP4L6y"
   },
   "source": [
    "### Import libraries and initialize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "mUxxhafP4KM9"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "from io import BytesIO\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "\n",
    "# BigQuery client.\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Google Cloud Storage client.\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Initialize Vertex AI SDK.\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwhKPE19djbK"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "In this section we will create the bucket with images in Google Cloud Storage, create the dataset in BigQuery, load the table with ground truth, and create the views that will serve for analysis of the results from Gemini and reporting in Looker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuTX-VHLWWSt"
   },
   "source": [
    "### Get sample images and upload them to a GCS bucket\n",
    "Images are a subset of the sports classification dataset in https://www.kaggle.com/datasets/gpiosenka/sports-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tfqc-oZqW1N4"
   },
   "outputs": [],
   "source": [
    "# TODO: update with url\n",
    "# Download sample data to notebook.\n",
    "!wget https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/data/sports_files.zip\n",
    "!unzip /content/sports_files.zip\n",
    "\n",
    "# Create bucket.\n",
    "!gcloud storage buckets create gs://{BUCKET_NAME} --location={LOCATION}\n",
    "\n",
    "# Copy images to bucket.\n",
    "!gcloud storage cp -r -n /content/sports_files/ gs://{BUCKET_NAME}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOKg8sxIZnzm"
   },
   "source": [
    "### Create BigQuery dataset and load table with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjWGl6V9ZvhV",
    "outputId": "fd61b025-da15-448f-a16b-475a6c273638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset arielj-argolis-1.text_extraction_3\n",
      "Loaded 274 rows.\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(dataset_id, project, location):\n",
    "    \"\"\"Creates a BigQuery dataset.\"\"\"\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = location\n",
    "\n",
    "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
    "    print(\"Created dataset {}.{}\".format(bq_client.project, dataset.dataset_id))\n",
    "\n",
    "\n",
    "def load_files_table_from_uri(files_table, uri):\n",
    "    \"\"\"Load ground truth table from a URI.\"\"\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=[\n",
    "            bigquery.SchemaField(\"path\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"label\", \"STRING\"),\n",
    "        ],\n",
    "        skip_leading_rows=1,\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    )\n",
    "    load_job = bq_client.load_table_from_uri(uri, files_table, job_config=job_config)\n",
    "    load_job.result()\n",
    "\n",
    "    destination_table = bq_client.get_table(files_table)\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "\n",
    "\n",
    "create_dataset(dataset_id=BQ_DATASET, project=PROJECT_ID, location=LOCATION)\n",
    "load_files_table_from_uri(files_table=FILES_TABLE, uri=SPORTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW4EngZRLlts"
   },
   "source": [
    "### Test image URIs from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRgVfFZIN7ae",
    "outputId": "f53c1f11-f619-44a4-f9fc-583ebeba2586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/tennis/064.jpg', 'train/tennis/045.jpg']\n"
     ]
    }
   ],
   "source": [
    "def get_filepaths(files_table):\n",
    "    \"\"\"Get filepaths from the ground truth table in BigQuery.\"\"\"\n",
    "    job = bq_client.query(\n",
    "        f\"\"\"\n",
    "      SELECT path\n",
    "      FROM {files_table}\"\"\"\n",
    "    )\n",
    "    return [row[0] for row in job.result()]\n",
    "\n",
    "\n",
    "images_uri = get_filepaths(files_table=FILES_TABLE)\n",
    "print(images_uri[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hVJ_n3P6AF4"
   },
   "source": [
    "### Create view of text generation results\n",
    "\n",
    "Run this only once to create the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbT4qLbTQ7iD",
    "outputId": "2ead0bb7-6383-4436-fb2f-8c958fe81d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VIEW: arielj-argolis-1.text_extraction_3.extraction_results\n"
     ]
    }
   ],
   "source": [
    "def create_text_generation_view(text_generation_table_prefix, results_view):\n",
    "    \"\"\"Creates a view of text extraction results.\"\"\"\n",
    "\n",
    "    view = bigquery.Table(results_view)\n",
    "\n",
    "    view.view_query = rf\"\"\"\n",
    "      WITH t1 AS\n",
    "      (\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          JSON_EXTRACT(response, '$[0].content.parts[0].text') AS json_data\n",
    "        FROM `{text_generation_table_prefix}_*`\n",
    "      ),\n",
    "      t2 AS (\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          REGEXP_EXTRACT(json_data, r'```json(.*)```') AS f\n",
    "        FROM t1\n",
    "      ),\n",
    "      t3 AS(\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          REPLACE(f, '\\\\n', '') AS f\n",
    "        FROM t2\n",
    "      ),\n",
    "      t4 AS (\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          REPLACE(f, '\\\\\"', '\"') AS f\n",
    "        FROM t3\n",
    "      ),\n",
    "      t5 AS (\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          JSON_QUERY(f, '$.sport') AS f\n",
    "        FROM t4\n",
    "      ),\n",
    "      t6 AS (\n",
    "        SELECT\n",
    "          evaluation_id,\n",
    "          evaluation_ts,\n",
    "          prompt_text,\n",
    "          gcs_uri,\n",
    "          REPLACE(f, '\"', '') AS f\n",
    "        FROM t5\n",
    "      )\n",
    "\n",
    "      SELECT\n",
    "        evaluation_id,\n",
    "        evaluation_ts,\n",
    "        prompt_text,\n",
    "        gcs_uri,\n",
    "        f AS label\n",
    "      FROM t6\"\"\"\n",
    "\n",
    "    # Make an API request to create the view.\n",
    "    view = bq_client.create_table(view, exists_ok=False)\n",
    "    print(f\"Created {view.table_type}: {str(view.reference)}\")\n",
    "\n",
    "\n",
    "create_text_generation_view(\n",
    "    text_generation_table_prefix=TEXT_GENERATION_TABLE_PREFIX, results_view=RESULTS_VIEW\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcyIaLMC62rs"
   },
   "source": [
    "### Create view of experiment evaluation\n",
    "\n",
    "Run this only once to create the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcZrWnI13H4F",
    "outputId": "8b3631aa-932e-4165-fadd-fb5e8c45e1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VIEW: arielj-argolis-1.text_extraction_3.evaluation\n"
     ]
    }
   ],
   "source": [
    "def create_evaluation_view(evaluation_view, files_table, results_view):\n",
    "    \"\"\"Creates a view of experiment evaluation.\"\"\"\n",
    "\n",
    "    view = bigquery.Table(evaluation_view)\n",
    "\n",
    "    view.view_query = f\"\"\"\n",
    "      WITH t1 AS (\n",
    "        SELECT\n",
    "          e.evaluation_id,\n",
    "          e.evaluation_ts,\n",
    "          e.prompt_text,\n",
    "          f.path,\n",
    "          f.label,\n",
    "          e.gcs_uri,\n",
    "          f.label = e.label AS correct\n",
    "        FROM `{files_table}` f\n",
    "        JOIN `{results_view}` e\n",
    "          ON f.path = e.gcs_uri\n",
    "      )\n",
    "\n",
    "      SELECT\n",
    "        evaluation_id,\n",
    "        evaluation_ts,\n",
    "        prompt_text,\n",
    "        path,\n",
    "        label,\n",
    "        correct\n",
    "      FROM t1\"\"\"\n",
    "\n",
    "    # Make an API request to create the view.\n",
    "    view = bq_client.create_table(view, exists_ok=False)\n",
    "    print(f\"Created {view.table_type}: {str(view.reference)}\")\n",
    "\n",
    "\n",
    "create_evaluation_view(\n",
    "    evaluation_view=EVALUATION_VIEW, files_table=FILES_TABLE, results_view=RESULTS_VIEW\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn2t64pkbQHq"
   },
   "source": [
    "## Define prompt and execute it via Gemini Batch Prediction API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xbq75NqxRXBO"
   },
   "source": [
    "### Define the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "bk-EpTp0uJR4"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "- Classify the sport from the image below in one of the following categories:\n",
    "* baseball\n",
    "* basketball\n",
    "* tennis\n",
    "* volleyball\n",
    "\n",
    "- Provide an answer in JSON format. 3. Example response:\n",
    "'{\"sport\": \"baseball\"}'\n",
    "\n",
    "- Image:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCGQhmmSRbgc"
   },
   "source": [
    "### Classify one image using the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kchsx7bdrGgf",
    "outputId": "45411834-7bee-4d00-8e60-6541df113b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blob_name: train/tennis/045.jpg\n",
      "response: ```json\n",
      "{\"sport\": \"tennis\"}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def download_blob_into_memory(bucket_name, blob_name):\n",
    "    \"\"\"Downloads a blob from GCS into memory.\"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "    contents = blob.download_as_bytes()\n",
    "    return contents\n",
    "\n",
    "\n",
    "def classify_image(model_id, prompt, bucket_name, blob_name):\n",
    "    \"\"\"Classifies an image.\"\"\"\n",
    "    model = GenerativeModel(model_id)\n",
    "    contents = download_blob_into_memory(bucket_name, blob_name)\n",
    "    encoded_image = base64.b64encode(contents).decode(\"utf-8\")\n",
    "    image_content = Part.from_data(\n",
    "        data=base64.b64decode(encoded_image), mime_type=\"image/jpeg\"\n",
    "    )\n",
    "    contents = [prompt, image_content]\n",
    "    response = model.generate_content(contents)\n",
    "    return response\n",
    "\n",
    "\n",
    "blob_name = get_filepaths(files_table=FILES_TABLE)[1]\n",
    "response = classify_image(\n",
    "    model_id=MODEL_ID, prompt=prompt, bucket_name=BUCKET_NAME, blob_name=blob_name\n",
    ")\n",
    "print(f\"blob_name: {blob_name}\")\n",
    "print(f\"response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q79hx4JINXZh"
   },
   "source": [
    "### Create a New Line JSON file applying the prompt to each of the images\n",
    "In this section, also an `evaluation_id` variable is created to identify the execution run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "_Dn4SStFOBak"
   },
   "outputs": [],
   "source": [
    "def create_newline_json_file(\n",
    "    prompt, evaluation_ts, evaluation_id, file_name, bucket_name, images_uri\n",
    "):\n",
    "    \"\"\"Creates a newline delimited JSON file.\"\"\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        for image_uri in images_uri:\n",
    "            contents = download_blob_into_memory(bucket_name, image_uri)\n",
    "            encoded_image = base64.b64encode(contents).decode(\"utf-8\")\n",
    "            request = {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [\n",
    "                            {\"text\": prompt},\n",
    "                            {\n",
    "                                \"inlineData\": {\n",
    "                                    \"mimeType\": \"image/jpeg\",\n",
    "                                    \"data\": encoded_image,\n",
    "                                }\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            line = {\n",
    "                \"evaluation_ts\": evaluation_ts,\n",
    "                \"evaluation_id\": evaluation_id,\n",
    "                \"prompt_text\": prompt,\n",
    "                \"gcs_uri\": image_uri,\n",
    "                \"request\": request,\n",
    "            }\n",
    "\n",
    "            outfile.write(json.dumps(line))\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "evaluation_ts = str(now)\n",
    "evaluation_id = f\"{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}\"\n",
    "json_file_name = f\"/tmp/{evaluation_id}.json\"\n",
    "\n",
    "create_newline_json_file(\n",
    "    prompt=prompt,\n",
    "    evaluation_ts=evaluation_ts,\n",
    "    evaluation_id=evaluation_id,\n",
    "    file_name=json_file_name,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    images_uri=images_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_g7H_anNcKm"
   },
   "source": [
    "### Upload the newline delimited JSON file to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5zHqg90nBtR",
    "outputId": "80fa2f12-68f6-47db-8aaf-852cd96bbfda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 274 rows and 5 columns to arielj-argolis-1.text_extraction_3.temp_prompts\n"
     ]
    }
   ],
   "source": [
    "def upload_newline_json_file(json_file_name, project_id, prompts_table):\n",
    "    \"\"\"Uploads a newline delimited JSON file to BigQuery.\"\"\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=[\n",
    "            bigquery.SchemaField(\"evaluation_ts\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"evaluation_id\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"prompt_text\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"request\", \"JSON\"),\n",
    "        ],\n",
    "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    )\n",
    "\n",
    "    with open(json_file_name, \"rb\") as source_file:\n",
    "        job = bq_client.load_table_from_file(\n",
    "            source_file, PROMPTS_TABLE, job_config=job_config\n",
    "        )\n",
    "\n",
    "    job.result()\n",
    "    table = bq_client.get_table(prompts_table)\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), prompts_table\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "upload_newline_json_file(\n",
    "    json_file_name=json_file_name, project_id=PROJECT_ID, prompts_table=PROMPTS_TABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LveMID56Ngo6"
   },
   "source": [
    "### Launch a Gemini Batch Prediction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NdypZy-TacS",
    "outputId": "a1df0622-287a-4e77-f280-d68afe94c843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/743100398377/locations/us-central1/batchPredictionJobs/5373658193635311616\",\n",
      "  \"displayName\": \"2024_7_25_11_19\",\n",
      "  \"model\": \"publishers/google/models/gemini-1.5-flash-001\",\n",
      "  \"inputConfig\": {\n",
      "    \"instancesFormat\": \"bigquery\",\n",
      "    \"bigquerySource\": {\n",
      "      \"inputUri\": \"bq://arielj-argolis-1.text_extraction_3.temp_prompts\"\n",
      "    }\n",
      "  },\n",
      "  \"outputConfig\": {\n",
      "    \"predictionsFormat\": \"bigquery\",\n",
      "    \"bigqueryDestination\": {\n",
      "      \"outputUri\": \"bq://arielj-argolis-1.text_extraction_3.results_2024_7_25_11_19\"\n",
      "    }\n",
      "  },\n",
      "  \"state\": \"JOB_STATE_PENDING\",\n",
      "  \"createTime\": \"2024-07-25T11:21:32.461969Z\",\n",
      "  \"updateTime\": \"2024-07-25T11:21:32.461969Z\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define table to store results from Gemini Batch Prediction.\n",
    "text_generation_table = f\"{TEXT_GENERATION_TABLE_PREFIX}_{evaluation_id}\"\n",
    "\n",
    "\n",
    "def create_batch_prediction_job(\n",
    "    project_id, model_id, prompts_table, text_generation_table\n",
    "):\n",
    "    \"\"\"Creates a Gemini batch prediction job.\"\"\"\n",
    "\n",
    "    gemini_batch_url = (\n",
    "        f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/\"\n",
    "        f\"locations/us-central1/batchPredictionJobs\"\n",
    "    )\n",
    "\n",
    "    # Get Authentication token.\n",
    "    creds, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    token = creds.token\n",
    "\n",
    "    # Build request.\n",
    "    request_data = {\n",
    "        \"displayName\": evaluation_id,\n",
    "        \"model\": f\"publishers/google/models/{model_id}\",\n",
    "        \"inputConfig\": {\n",
    "            \"instancesFormat\": \"bigquery\",\n",
    "            \"bigquerySource\": {\"inputUri\": f\"bq://{prompts_table}\"},\n",
    "        },\n",
    "        \"outputConfig\": {\n",
    "            \"predictionsFormat\": \"bigquery\",\n",
    "            \"bigqueryDestination\": {\"outputUri\": f\"bq://{text_generation_table}\"},\n",
    "        },\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "    }\n",
    "\n",
    "    batch_response = requests.post(gemini_batch_url, json=request_data, headers=headers)\n",
    "    print(batch_response.text)\n",
    "\n",
    "    # Get job id of the request.\n",
    "    batch_response_json = batch_response.json()\n",
    "    job_name = batch_response_json[\"name\"]\n",
    "    job_id = job_name.split(\"/\")[-1]\n",
    "\n",
    "    # Get state of the request.\n",
    "    job_state = batch_response_json[\"state\"]\n",
    "    return job_id, job_state\n",
    "\n",
    "\n",
    "job_id, job_state = create_batch_prediction_job(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    prompts_table=PROMPTS_TABLE,\n",
    "    text_generation_table=text_generation_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLlsbnbXPpgK"
   },
   "source": [
    "### Check state of the Gemini Batch Prediction request until completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9atOKsOUCs0",
    "outputId": "690f090f-7f89-4a26-9fd1-b2d58998cc0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status 2024-07-25 11:21:42.653686: JOB_STATE_PENDING\n",
      "Status 2024-07-25 11:21:43.049581: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:22:13.409234: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:22:43.835615: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:23:14.256927: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:23:44.634046: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:24:15.031125: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:24:45.450595: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:25:15.830552: JOB_STATE_QUEUED\n",
      "Status 2024-07-25 11:25:46.277329: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "def check_job_state(project_id, job_id, last_job_state):\n",
    "    \"\"\"Checks status of the Gemini batch text generation request.\"\"\"\n",
    "\n",
    "    get_status_url = (\n",
    "        f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/\"\n",
    "        f\"locations/us-central1/batchPredictionJobs/{job_id}\"\n",
    "    )\n",
    "\n",
    "    # Get Authentication token.\n",
    "    creds, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    token = creds.token\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "    }\n",
    "\n",
    "    job_state = last_job_state\n",
    "    now = datetime.datetime.now()\n",
    "    print(f\"Status {now}: {job_state}\")\n",
    "\n",
    "    while job_state not in STOP_STATES:\n",
    "        state_response = requests.get(get_status_url, headers=headers)\n",
    "        state_response_json = state_response.json()\n",
    "        job_state = state_response_json[\"state\"]\n",
    "        now = datetime.datetime.now()\n",
    "        print(f\"Status {now}: {job_state}\")\n",
    "        if job_state not in STOP_STATES:\n",
    "            time.sleep(30)\n",
    "\n",
    "\n",
    "check_job_state(project_id=PROJECT_ID, job_id=job_id, last_job_state=job_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTl8-Cbg7Ll5"
   },
   "source": [
    "### List sample of text generation results from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0jHGtZEUK88",
    "outputId": "1c797b34-2113-4f08-ee6b-4278282fefd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"sport\": \"volleyball\"}\n",
      "```\n",
      "```json\n",
      "{\"sport\": \"volleyball\"}\n",
      "```\n",
      "```json\n",
      "{\"sport\": \"tennis\"}\n",
      "```\n",
      "```json\n",
      "{\"sport\": \"tennis\"}\n",
      "```\n",
      "```json\n",
      "{\"sport\": \"tennis\"}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def print_text_generation_results(text_generation_table):\n",
    "    \"\"\"Lists text generation results from BigQuery.\"\"\"\n",
    "\n",
    "    job = bq_client.query(\n",
    "        f\"\"\"\n",
    "      SELECT gcs_uri, response, status, processed_time\n",
    "      FROM {text_generation_table}\n",
    "      LIMIT 5\"\"\"\n",
    "    )\n",
    "\n",
    "    for row in job.result():\n",
    "        json_row = json.loads(row[1])\n",
    "        json_response = json_row[0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        print(json_response)\n",
    "\n",
    "\n",
    "print_text_generation_results(text_generation_table=text_generation_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01saqXPQbuIS"
   },
   "source": [
    "## Analyze results in BigQuery and Looker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJvttnjyZxIs"
   },
   "source": [
    "### Copy a Looker Studio dashboard to analyze results\n",
    "\n",
    "1. Make a copy of this [Looker Studio dashboard](https://lookerstudio.google.com/reporting/6dd5a7e8-b353-4dde-9bd8-72eb7b501559)\n",
    "1. Connect dashboard to your view"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
