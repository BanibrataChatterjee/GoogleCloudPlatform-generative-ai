{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Narrate a Multi-character Story with Text-to-Speech and Gemini\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/multimodal_rag_langchain.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/getting-started/intro_palm_api.ipynb\">\n",
    "      <svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" preserveAspectRatio=\"xMidYMid meet\" focusable=\"false\" style=\"pointer-events: none; width: 32px; height: 32px;\"><g><path d=\"M4.54,9.46,2.19,7.1a6.93,6.93,0,0,0,0,9.79l2.36-2.36A3.59,3.59,0,0,1,4.54,9.46Z\" style=\"\" fill=\"#1A73E8\"></path><path d=\"M2.19,7.1,4.54,9.46a3.59,3.59,0,0,1,5.08,0l1.71-2.93h0l-.1-.08h0A6.93,6.93,0,0,0,2.19,7.1Z\" style=\"\" fill=\"#669df6\"></path><path d=\"M11.34,17.46h0L9.62,14.54a3.59,3.59,0,0,1-5.08,0L2.19,16.9a6.93,6.93,0,0,0,9,.65l.11-.09\" style=\"\" fill=\"#669df6\"></path><path d=\"M12,7.1a6.93,6.93,0,0,0,0,9.79l2.36-2.36a3.59,3.59,0,1,1,5.08-5.08L21.81,7.1A6.93,6.93,0,0,0,12,7.1Z\" style=\"\" fill=\"#669df6\"></path><path d=\"M21.81,7.1,19.46,9.46a3.59,3.59,0,0,1-5.08,5.08L12,16.9A6.93,6.93,0,0,0,21.81,7.1Z\" style=\"\" fill=\"#1A73E8\"></path></g></svg><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/multimodal_rag_langchain.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/multimodal_rag_langchain.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "---\n",
    "\n",
    "* Author: Holt Skinner\n",
    "* Created: Jan 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demostrates how to use the [Text-to-Speech API](https://cloud.google.com/text-to-speech) to read a story with each character having a distinct voice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "This tutorial uses the following Google Cloud AI services and resources:\n",
    "\n",
    "- [Cloud Text-to-Speech API](https://cloud.google.com/text-to-speech/docs)\n",
    "- Cloud Storage\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Parse the input story text in play script format. (`Character: Lines`)\n",
    "- Assign each character to a voice.\n",
    "- Synthesize each line based on character voice.\n",
    "- Combine audio files into one MP3 file.\n",
    "\n",
    "Planned expansions:\n",
    "\n",
    "- Upload audio to Cloud Storage\n",
    "- Read in story text using [Document AI OCR](https://cloud.google.com/document-ai)\n",
    "- Convert story to play script format using Gemini.\n",
    "- Create alternative implementation using LangChain.\n",
    "- Assign character voices using Gemini.\n",
    "- Add [Journey voices](https://cloud.google.com/text-to-speech/docs/voice-types#journey_voices) once more voices are supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Text-to-Speech\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Text-to-Speech pricing](https://cloud.google.com/text-to-speech/pricing),\n",
    "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNSWiCNPjh_p"
   },
   "source": [
    "### Install Vertex AI SDK, other packages and their dependencies\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2b4ef9b72d43",
    "outputId": "6703326c-af97-4491-d931-5c66e5b256ac"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install --user --upgrade -q google-cloud-aiplatform google-cloud-texttospeech pydub gender-guesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running on a Mac, you will need to install [FFmpeg](https://ffmpeg.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbWwuHK8j1xm"
   },
   "source": [
    "### Colab only: Run the following cell to restart the kernel.\n",
    "\n",
    "***Colab only***: Run the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbMFqPZ3tnwz"
   },
   "source": [
    "Set the project and region.\n",
    "\n",
    "* Please note the **available regions** for Text-to-Speech, see [documentation](https://cloud.google.com/text-to-speech/docs/endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjSsu6cmUdEx"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "LOCATION = \"us\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opUxT_k5TdgP"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "\n",
    "* If you are using **Colab** to run this notebook, run the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbNgv4q1T2Mi"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import vertexai\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # Initialize Vertex AI\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Download source texts from Google Cloud Storage\n",
    "\n",
    "This public bucket contains some stories generated by PaLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIq7R4HZCfIc",
    "outputId": "dd3caf14-eab3-451c-fd5f-e726a45c62c5"
   },
   "outputs": [],
   "source": [
    "! gsutil cp gs://github-repo/speech/storytelling/*.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import sys\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from gender_guesser.detector import Detector\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import texttospeech_v1beta1 as texttospeech\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LANGUAGE = \"en\"\n",
    "# Voice used for narration, scene details, etc.\n",
    "DEFAULT_VOICE = (\"en-GB-Neural2-B\", \"en-GB\")\n",
    "\n",
    "tts_client = texttospeech.TextToSpeechClient(\n",
    "    client_options=ClientOptions(api_endpoint=f\"{LOCATION}-texttospeech.googleapis.com\")\n",
    ")\n",
    "gender_detector = Detector()\n",
    "\n",
    "SILENCE_LENGTH = 200\n",
    "TXT_EXTENSION = \".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5CEc4-Wrjk2"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYx2wwhjrmD6"
   },
   "outputs": [],
   "source": [
    "def list_voices_by_gender(\n",
    "    language_code: str = DEFAULT_LANGUAGE,\n",
    ") -> Tuple[Dict[str, List], int]:\n",
    "    gender_to_voices: Dict[str, List[Tuple[str, str]]] = {}\n",
    "    total_voices = 0\n",
    "\n",
    "    # Performs the list voices request\n",
    "    response = tts_client.list_voices(language_code=language_code)\n",
    "\n",
    "    for voice in response.voices:\n",
    "        if \"Neural2\" not in voice.name or DEFAULT_VOICE[0] == voice.name:\n",
    "            continue\n",
    "\n",
    "        ssml_gender = texttospeech.SsmlVoiceGender(voice.ssml_gender).name.lower()\n",
    "\n",
    "        if gender_to_voices.get(ssml_gender):\n",
    "            gender_to_voices[ssml_gender].append((voice.name, voice.language_codes[0]))\n",
    "        else:\n",
    "            gender_to_voices[ssml_gender] = [(voice.name, voice.language_codes[0])]\n",
    "\n",
    "        total_voices += 1\n",
    "\n",
    "    return gender_to_voices, total_voices\n",
    "\n",
    "\n",
    "def print_gender_map(gender_to_voices: Dict[str, List]):\n",
    "    print(\"Gender\\t| Voice Name\")\n",
    "    for gender, voices in gender_to_voices.items():\n",
    "        for voice in voices:\n",
    "            print(f\"{gender}\\t| {voice}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def create_character_map(\n",
    "    names: List[str], gender_to_voices: Dict[str, List]\n",
    ") -> Dict[str, Tuple]:\n",
    "    character_to_voice: Dict[str, Tuple] = {}\n",
    "    supported_genders = list(gender_to_voices.keys())\n",
    "\n",
    "    # For character names that are not supported by gender_guesser\n",
    "    CHARACTER_GENDER = {\"Macbeth\": \"male\", \"Lady Macbeth\": \"female\", \"Ariel\": \"female\"}\n",
    "\n",
    "    for name in names:\n",
    "        if name == \"Narrator\":\n",
    "            character_to_voice[name] = DEFAULT_VOICE\n",
    "            continue\n",
    "\n",
    "        if name in CHARACTER_GENDER:\n",
    "            gender = CHARACTER_GENDER[name]\n",
    "        else:\n",
    "            gender = gender_detector.get_gender(name)\n",
    "\n",
    "        # If gender is indeterminate/androgynous, pick random one\n",
    "        if gender not in supported_genders:\n",
    "            gender = choice(supported_genders)\n",
    "\n",
    "        # Assign Voice to Character and don't reuse.\n",
    "        voice = choice(gender_to_voices[gender])\n",
    "        gender_to_voices[gender].remove(voice)\n",
    "        character_to_voice[name] = voice\n",
    "\n",
    "    return character_to_voice\n",
    "\n",
    "\n",
    "def print_character_map(character_to_voice: Dict[str, Tuple]):\n",
    "    print(\"Character\\t| Voice Name\")\n",
    "    for name, voice in character_to_voice.items():\n",
    "        print(f\"{name}\\t| {voice}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def synthesize_text(\n",
    "    text: str, output: str, voice_name: str, language_code: str = DEFAULT_LANGUAGE\n",
    "):\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=language_code, name=voice_name\n",
    "    )\n",
    "\n",
    "    # Note: you can pass in multiple effects_profile_id. They will be applied\n",
    "    # in the same order they are provided.\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "    )\n",
    "\n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=input_text, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(output, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "\n",
    "\n",
    "def combine_audio_files(audio_files: List, filename: str) -> str:\n",
    "    full_audio = AudioSegment.silent(duration=SILENCE_LENGTH)\n",
    "\n",
    "    for file in audio_files:\n",
    "        sound = AudioSegment.from_mp3(file)\n",
    "        silence = AudioSegment.silent(duration=SILENCE_LENGTH)\n",
    "        full_audio = full_audio + sound + silence\n",
    "\n",
    "        os.remove(file)\n",
    "\n",
    "    outfile_name = f\"{filename}-complete.mp3\"\n",
    "    full_audio.export(outfile_name, format=\"mp3\")\n",
    "    return outfile_name\n",
    "\n",
    "\n",
    "def get_characters(input_file) -> List:\n",
    "    character_list = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = lines.index(\"Characters:\\n\")\n",
    "\n",
    "    for i in range(start_line + 2, len(lines)):\n",
    "        if lines[i] == \"\\n\":\n",
    "            break\n",
    "        character_list.append(lines[i].strip())\n",
    "    return character_list\n",
    "\n",
    "\n",
    "def parse_file(input_file: str, character_to_voice: Dict[str, Tuple]) -> List[str]:\n",
    "    with open(input_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    line_number = 1\n",
    "    output_files = []\n",
    "    filename = file_prefix(input_file)\n",
    "\n",
    "    for line in lines:\n",
    "        split_line = line.strip().split(\": \", 1)\n",
    "\n",
    "        character = split_line[0]\n",
    "        # Skip blank lines\n",
    "        if not character:\n",
    "            continue\n",
    "\n",
    "        voice = character_to_voice.get(character, DEFAULT_VOICE)\n",
    "\n",
    "        if len(split_line) <= 1:\n",
    "            dialogue = split_line[0]\n",
    "        elif \"Scene\" in split_line[0]:\n",
    "            dialogue = split_line[0] + split_line[1]\n",
    "        else:\n",
    "            dialogue = split_line[1]\n",
    "\n",
    "        output_file = f\"{filename}-{line_number}.mp3\"\n",
    "        output_files.append(output_file)\n",
    "        synthesize_text(dialogue, output_file, voice[0], voice[1])\n",
    "        line_number += 1\n",
    "\n",
    "    return output_files\n",
    "\n",
    "\n",
    "def file_prefix(input_file: str) -> str:\n",
    "    return input_file.replace(TXT_EXTENSION, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eaHokbL2nS9"
   },
   "source": [
    "## Call the Text-to-Speech API with script content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KqGXuRVuBDf"
   },
   "outputs": [],
   "source": [
    "input_file = \"Macbeth.txt\"  # @param {type:\"string\"}\n",
    "\n",
    "# Get voices and genders\n",
    "gender_to_voices, total_voices = list_voices_by_gender()\n",
    "print_gender_map(gender_to_voices)\n",
    "\n",
    "# List all characters\n",
    "character_list = get_characters(input_file)\n",
    "\n",
    "if len(character_list) > total_voices:\n",
    "    print(f\"Too many characters {len(character_list)}. Max {total_voices}\")\n",
    "\n",
    "# Map Characters to Voices\n",
    "character_to_voice = create_character_map(character_list, gender_to_voices)\n",
    "print_character_map(character_to_voice)\n",
    "\n",
    "# Parse input text and output each line as audio\n",
    "output_files = parse_file(input_file, character_to_voice)\n",
    "\n",
    "# Combine audio files into a single file\n",
    "outfile_name = combine_audio_files(output_files, file_prefix(input_file))\n",
    "print(f\"Audio content written to file {outfile_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(outfile_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
